{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_11212\\2292805398.py:1: DtypeWarning: Columns (4,13,14,16,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"train.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['surname','forename','dob','positionText_x','number','time_x','fastestLap','rank','fastestLapTime','max_speed',])\n",
    "df = df.drop(columns=['grand_prix','date','time_y','url_x','fp1_date',\n",
    "                      'fp2_date','fp3_date','quali_date','quali_time','sprint_date','sprint_time','driverRef',\n",
    "                     'driver_num','driver_code','nationality','url_y','positionText_y','constructorRef',\n",
    "                     'company','nationality_y','url'])\n",
    "df = df.drop(columns=['fp1_time','fp2_time','fp3_time'])\n",
    "df = df.drop(columns=['positionOrder'])\n",
    "df = df.drop(columns=['resultId',])\n",
    "df = df.drop(columns=['driverStandingsId','position_x'])\n",
    "df = df.drop(columns=['statusId'])\n",
    "df['is_finished'] = df['status'].apply(lambda x: 1 if x == 'Finished' else 0)\n",
    "df['avg_grid_position'] = df.groupby(['driverId','year'])['grid'].transform(lambda x: x.expanding().mean().shift(1))\n",
    "\n",
    "# Cumulative points up to the current lap, excluding the current lap's points\n",
    "df['cumulative_points'] = df.groupby(['driverId', 'racerId'])['points_y'].cumsum().shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['racerId', 'driverId', 'constructorId', 'grid', 'points', 'laps',\n",
      "       'timetaken_in_millisec', 'year', 'round', 'circuitId', 'raceId_y',\n",
      "       'points_y', 'position', 'wins', 'result_driver_standing', 'is_finished',\n",
      "       'avg_grid_position', 'cumulative_points'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"timetaken_in_millisec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "racerId                   0.146104\n",
      "driverId                  0.241365\n",
      "constructorId             0.165706\n",
      "grid                      0.235240\n",
      "points                   -0.220597\n",
      "laps                     -0.084758\n",
      "year                     -0.270743\n",
      "round                    -0.068691\n",
      "circuitId                 0.093777\n",
      "raceId_y                  0.100520\n",
      "points_y                 -0.421678\n",
      "position                  1.000000\n",
      "wins                     -0.388797\n",
      "result_driver_standing    0.092763\n",
      "is_finished              -0.235115\n",
      "avg_grid_position         0.278260\n",
      "cumulative_points        -0.233852\n",
      "Name: position, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#take the correlation of the columns with position\n",
    "print(df.corr()['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_11212\\2719348433.py:1: DtypeWarning: Columns (13,16,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test=pd.read_csv(\"validation.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv(\"validation.csv\")\n",
    "#df and df_test have the intersection of columns in common\n",
    "cols=list(set(df.columns).intersection(set(df_test.columns)))\n",
    "df=df[cols]\n",
    "df_test=df_test[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "racerId                  -0.025206\n",
      "grid                      0.365640\n",
      "year                     -0.022140\n",
      "laps                     -0.070981\n",
      "result_driver_standing    0.085667\n",
      "position                  1.000000\n",
      "round                    -0.004298\n",
      "circuitId                -0.006027\n",
      "points                   -0.349921\n",
      "points_y                 -0.641362\n",
      "wins                     -0.504762\n",
      "driverId                  0.320787\n",
      "raceId_y                  0.113942\n",
      "constructorId             0.081673\n",
      "Name: position, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#correlation of the columns with position\n",
    "print(df_test.corr()['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['position'])\n",
    "y=df['position']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test=df_test.drop(columns=['position'])\n",
    "y_test=df_test['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train > 20, 20, y_train)\n",
    "y_val = np.where(y_val > 20, 20, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train -= 1\n",
    "y_val -= 1\n",
    "y_test -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.where(y_test > 20, 20, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightgbm) (1.13.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: C:\\Users\\Asus\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightgbm\\engine.py:204: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 6.83897\tvalid_1's rmse: 6.88001\n",
      "[20]\ttraining's rmse: 5.49415\tvalid_1's rmse: 5.53027\n",
      "[30]\ttraining's rmse: 4.88407\tvalid_1's rmse: 4.91573\n",
      "[40]\ttraining's rmse: 4.5914\tvalid_1's rmse: 4.61936\n",
      "[50]\ttraining's rmse: 4.43421\tvalid_1's rmse: 4.45983\n",
      "[60]\ttraining's rmse: 4.33229\tvalid_1's rmse: 4.35581\n",
      "[70]\ttraining's rmse: 4.25692\tvalid_1's rmse: 4.28007\n",
      "[80]\ttraining's rmse: 4.19649\tvalid_1's rmse: 4.21926\n",
      "[90]\ttraining's rmse: 4.13902\tvalid_1's rmse: 4.16189\n",
      "[100]\ttraining's rmse: 4.0893\tvalid_1's rmse: 4.11246\n",
      "[110]\ttraining's rmse: 4.04856\tvalid_1's rmse: 4.07225\n",
      "[120]\ttraining's rmse: 4.00722\tvalid_1's rmse: 4.03156\n",
      "[130]\ttraining's rmse: 3.97178\tvalid_1's rmse: 3.99651\n",
      "[140]\ttraining's rmse: 3.93747\tvalid_1's rmse: 3.9625\n",
      "[150]\ttraining's rmse: 3.90238\tvalid_1's rmse: 3.92843\n",
      "[160]\ttraining's rmse: 3.8718\tvalid_1's rmse: 3.89802\n",
      "[170]\ttraining's rmse: 3.84806\tvalid_1's rmse: 3.87409\n",
      "[180]\ttraining's rmse: 3.82199\tvalid_1's rmse: 3.84837\n",
      "[190]\ttraining's rmse: 3.80251\tvalid_1's rmse: 3.8291\n",
      "[200]\ttraining's rmse: 3.77985\tvalid_1's rmse: 3.80694\n",
      "[210]\ttraining's rmse: 3.75722\tvalid_1's rmse: 3.786\n",
      "[220]\ttraining's rmse: 3.73849\tvalid_1's rmse: 3.76801\n",
      "[230]\ttraining's rmse: 3.71618\tvalid_1's rmse: 3.74586\n",
      "[240]\ttraining's rmse: 3.69514\tvalid_1's rmse: 3.7253\n",
      "[250]\ttraining's rmse: 3.67532\tvalid_1's rmse: 3.70592\n",
      "[260]\ttraining's rmse: 3.66315\tvalid_1's rmse: 3.69429\n",
      "[270]\ttraining's rmse: 3.64431\tvalid_1's rmse: 3.67561\n",
      "[280]\ttraining's rmse: 3.63113\tvalid_1's rmse: 3.66271\n",
      "[290]\ttraining's rmse: 3.61526\tvalid_1's rmse: 3.64727\n",
      "[300]\ttraining's rmse: 3.59632\tvalid_1's rmse: 3.62862\n",
      "[310]\ttraining's rmse: 3.57933\tvalid_1's rmse: 3.61165\n",
      "[320]\ttraining's rmse: 3.56678\tvalid_1's rmse: 3.59928\n",
      "[330]\ttraining's rmse: 3.55166\tvalid_1's rmse: 3.58451\n",
      "[340]\ttraining's rmse: 3.53335\tvalid_1's rmse: 3.56619\n",
      "[350]\ttraining's rmse: 3.52628\tvalid_1's rmse: 3.55999\n",
      "[360]\ttraining's rmse: 3.51212\tvalid_1's rmse: 3.54639\n",
      "[370]\ttraining's rmse: 3.49871\tvalid_1's rmse: 3.5341\n",
      "[380]\ttraining's rmse: 3.47789\tvalid_1's rmse: 3.51333\n",
      "[390]\ttraining's rmse: 3.46439\tvalid_1's rmse: 3.50005\n",
      "[400]\ttraining's rmse: 3.45125\tvalid_1's rmse: 3.48689\n",
      "[410]\ttraining's rmse: 3.44198\tvalid_1's rmse: 3.47759\n",
      "[420]\ttraining's rmse: 3.42777\tvalid_1's rmse: 3.46332\n",
      "[430]\ttraining's rmse: 3.41855\tvalid_1's rmse: 3.45392\n",
      "[440]\ttraining's rmse: 3.40981\tvalid_1's rmse: 3.44535\n",
      "[450]\ttraining's rmse: 3.40125\tvalid_1's rmse: 3.43719\n",
      "[460]\ttraining's rmse: 3.39084\tvalid_1's rmse: 3.42665\n",
      "[470]\ttraining's rmse: 3.37648\tvalid_1's rmse: 3.41242\n",
      "[480]\ttraining's rmse: 3.36301\tvalid_1's rmse: 3.39907\n",
      "[490]\ttraining's rmse: 3.3542\tvalid_1's rmse: 3.39033\n",
      "[500]\ttraining's rmse: 3.34542\tvalid_1's rmse: 3.38177\n",
      "[510]\ttraining's rmse: 3.33379\tvalid_1's rmse: 3.37078\n",
      "[520]\ttraining's rmse: 3.32151\tvalid_1's rmse: 3.35849\n",
      "[530]\ttraining's rmse: 3.31546\tvalid_1's rmse: 3.35263\n",
      "[540]\ttraining's rmse: 3.30835\tvalid_1's rmse: 3.34555\n",
      "[550]\ttraining's rmse: 3.29454\tvalid_1's rmse: 3.33141\n",
      "[560]\ttraining's rmse: 3.28762\tvalid_1's rmse: 3.32493\n",
      "[570]\ttraining's rmse: 3.27418\tvalid_1's rmse: 3.3111\n",
      "[580]\ttraining's rmse: 3.26638\tvalid_1's rmse: 3.30366\n",
      "[590]\ttraining's rmse: 3.25633\tvalid_1's rmse: 3.29369\n",
      "[600]\ttraining's rmse: 3.24902\tvalid_1's rmse: 3.28676\n",
      "[610]\ttraining's rmse: 3.23616\tvalid_1's rmse: 3.27369\n",
      "[620]\ttraining's rmse: 3.22692\tvalid_1's rmse: 3.26463\n",
      "[630]\ttraining's rmse: 3.21929\tvalid_1's rmse: 3.25767\n",
      "[640]\ttraining's rmse: 3.21363\tvalid_1's rmse: 3.25209\n",
      "[650]\ttraining's rmse: 3.20074\tvalid_1's rmse: 3.23945\n",
      "[660]\ttraining's rmse: 3.1948\tvalid_1's rmse: 3.23361\n",
      "[670]\ttraining's rmse: 3.18862\tvalid_1's rmse: 3.2278\n",
      "[680]\ttraining's rmse: 3.18143\tvalid_1's rmse: 3.22074\n",
      "[690]\ttraining's rmse: 3.17163\tvalid_1's rmse: 3.21099\n",
      "[700]\ttraining's rmse: 3.16726\tvalid_1's rmse: 3.20698\n",
      "[710]\ttraining's rmse: 3.15379\tvalid_1's rmse: 3.19364\n",
      "[720]\ttraining's rmse: 3.14908\tvalid_1's rmse: 3.18934\n",
      "[730]\ttraining's rmse: 3.1373\tvalid_1's rmse: 3.17787\n",
      "[740]\ttraining's rmse: 3.12995\tvalid_1's rmse: 3.17083\n",
      "[750]\ttraining's rmse: 3.12391\tvalid_1's rmse: 3.16549\n",
      "[760]\ttraining's rmse: 3.1171\tvalid_1's rmse: 3.15942\n",
      "[770]\ttraining's rmse: 3.10799\tvalid_1's rmse: 3.15043\n",
      "[780]\ttraining's rmse: 3.1025\tvalid_1's rmse: 3.14511\n",
      "[790]\ttraining's rmse: 3.09421\tvalid_1's rmse: 3.13716\n",
      "[800]\ttraining's rmse: 3.08843\tvalid_1's rmse: 3.13182\n",
      "[810]\ttraining's rmse: 3.08273\tvalid_1's rmse: 3.1263\n",
      "[820]\ttraining's rmse: 3.07855\tvalid_1's rmse: 3.12229\n",
      "[830]\ttraining's rmse: 3.07038\tvalid_1's rmse: 3.11442\n",
      "[840]\ttraining's rmse: 3.06121\tvalid_1's rmse: 3.10553\n",
      "[850]\ttraining's rmse: 3.05116\tvalid_1's rmse: 3.09566\n",
      "[860]\ttraining's rmse: 3.04546\tvalid_1's rmse: 3.09027\n",
      "[870]\ttraining's rmse: 3.03701\tvalid_1's rmse: 3.0818\n",
      "[880]\ttraining's rmse: 3.02946\tvalid_1's rmse: 3.07442\n",
      "[890]\ttraining's rmse: 3.02386\tvalid_1's rmse: 3.06912\n",
      "[900]\ttraining's rmse: 3.01829\tvalid_1's rmse: 3.06382\n",
      "[910]\ttraining's rmse: 3.01128\tvalid_1's rmse: 3.05714\n",
      "[920]\ttraining's rmse: 3.00273\tvalid_1's rmse: 3.04875\n",
      "[930]\ttraining's rmse: 2.99785\tvalid_1's rmse: 3.04394\n",
      "[940]\ttraining's rmse: 2.99311\tvalid_1's rmse: 3.03958\n",
      "[950]\ttraining's rmse: 2.98607\tvalid_1's rmse: 3.03287\n",
      "[960]\ttraining's rmse: 2.97935\tvalid_1's rmse: 3.02608\n",
      "[970]\ttraining's rmse: 2.97437\tvalid_1's rmse: 3.02112\n",
      "[980]\ttraining's rmse: 2.96899\tvalid_1's rmse: 3.01579\n",
      "[990]\ttraining's rmse: 2.96383\tvalid_1's rmse: 3.01088\n",
      "[1000]\ttraining's rmse: 2.95954\tvalid_1's rmse: 3.00667\n",
      "[1010]\ttraining's rmse: 2.95284\tvalid_1's rmse: 3.00067\n",
      "[1020]\ttraining's rmse: 2.94895\tvalid_1's rmse: 2.99699\n",
      "[1030]\ttraining's rmse: 2.94273\tvalid_1's rmse: 2.99105\n",
      "[1040]\ttraining's rmse: 2.93581\tvalid_1's rmse: 2.98411\n",
      "[1050]\ttraining's rmse: 2.93034\tvalid_1's rmse: 2.97872\n",
      "[1060]\ttraining's rmse: 2.92448\tvalid_1's rmse: 2.97307\n",
      "[1070]\ttraining's rmse: 2.91805\tvalid_1's rmse: 2.96694\n",
      "[1080]\ttraining's rmse: 2.91468\tvalid_1's rmse: 2.96373\n",
      "[1090]\ttraining's rmse: 2.91129\tvalid_1's rmse: 2.96077\n",
      "[1100]\ttraining's rmse: 2.9057\tvalid_1's rmse: 2.95527\n",
      "[1110]\ttraining's rmse: 2.90018\tvalid_1's rmse: 2.9499\n",
      "[1120]\ttraining's rmse: 2.89441\tvalid_1's rmse: 2.94404\n",
      "[1130]\ttraining's rmse: 2.88965\tvalid_1's rmse: 2.93991\n",
      "[1140]\ttraining's rmse: 2.88158\tvalid_1's rmse: 2.93181\n",
      "[1150]\ttraining's rmse: 2.87796\tvalid_1's rmse: 2.92815\n",
      "[1160]\ttraining's rmse: 2.87422\tvalid_1's rmse: 2.92453\n",
      "[1170]\ttraining's rmse: 2.86992\tvalid_1's rmse: 2.92033\n",
      "[1180]\ttraining's rmse: 2.86567\tvalid_1's rmse: 2.91616\n",
      "[1190]\ttraining's rmse: 2.85827\tvalid_1's rmse: 2.90861\n",
      "[1200]\ttraining's rmse: 2.85373\tvalid_1's rmse: 2.90401\n",
      "[1210]\ttraining's rmse: 2.84993\tvalid_1's rmse: 2.90044\n",
      "[1220]\ttraining's rmse: 2.84424\tvalid_1's rmse: 2.89475\n",
      "[1230]\ttraining's rmse: 2.83846\tvalid_1's rmse: 2.88909\n",
      "[1240]\ttraining's rmse: 2.83181\tvalid_1's rmse: 2.88221\n",
      "[1250]\ttraining's rmse: 2.82665\tvalid_1's rmse: 2.87699\n",
      "[1260]\ttraining's rmse: 2.81856\tvalid_1's rmse: 2.86899\n",
      "[1270]\ttraining's rmse: 2.81289\tvalid_1's rmse: 2.86346\n",
      "[1280]\ttraining's rmse: 2.80842\tvalid_1's rmse: 2.8595\n",
      "[1290]\ttraining's rmse: 2.80318\tvalid_1's rmse: 2.85428\n",
      "[1300]\ttraining's rmse: 2.79895\tvalid_1's rmse: 2.85025\n",
      "[1310]\ttraining's rmse: 2.79633\tvalid_1's rmse: 2.84791\n",
      "[1320]\ttraining's rmse: 2.79236\tvalid_1's rmse: 2.84405\n",
      "[1330]\ttraining's rmse: 2.78598\tvalid_1's rmse: 2.83792\n",
      "[1340]\ttraining's rmse: 2.78005\tvalid_1's rmse: 2.83202\n",
      "[1350]\ttraining's rmse: 2.77512\tvalid_1's rmse: 2.82724\n",
      "[1360]\ttraining's rmse: 2.77106\tvalid_1's rmse: 2.8233\n",
      "[1370]\ttraining's rmse: 2.76718\tvalid_1's rmse: 2.81945\n",
      "[1380]\ttraining's rmse: 2.76353\tvalid_1's rmse: 2.81596\n",
      "[1390]\ttraining's rmse: 2.75602\tvalid_1's rmse: 2.80863\n",
      "[1400]\ttraining's rmse: 2.75036\tvalid_1's rmse: 2.80319\n",
      "[1410]\ttraining's rmse: 2.74482\tvalid_1's rmse: 2.79777\n",
      "[1420]\ttraining's rmse: 2.74147\tvalid_1's rmse: 2.79461\n",
      "[1430]\ttraining's rmse: 2.73663\tvalid_1's rmse: 2.78979\n",
      "[1440]\ttraining's rmse: 2.7332\tvalid_1's rmse: 2.78649\n",
      "[1450]\ttraining's rmse: 2.72863\tvalid_1's rmse: 2.78233\n",
      "[1460]\ttraining's rmse: 2.7233\tvalid_1's rmse: 2.77719\n",
      "[1470]\ttraining's rmse: 2.71956\tvalid_1's rmse: 2.77354\n",
      "[1480]\ttraining's rmse: 2.71448\tvalid_1's rmse: 2.76859\n",
      "[1490]\ttraining's rmse: 2.70954\tvalid_1's rmse: 2.76377\n",
      "[1500]\ttraining's rmse: 2.70384\tvalid_1's rmse: 2.7581\n",
      "[1510]\ttraining's rmse: 2.69878\tvalid_1's rmse: 2.75333\n",
      "[1520]\ttraining's rmse: 2.69333\tvalid_1's rmse: 2.74799\n",
      "[1530]\ttraining's rmse: 2.68867\tvalid_1's rmse: 2.74395\n",
      "[1540]\ttraining's rmse: 2.68631\tvalid_1's rmse: 2.74193\n",
      "[1550]\ttraining's rmse: 2.68295\tvalid_1's rmse: 2.73886\n",
      "[1560]\ttraining's rmse: 2.67999\tvalid_1's rmse: 2.73639\n",
      "[1570]\ttraining's rmse: 2.67553\tvalid_1's rmse: 2.73202\n",
      "[1580]\ttraining's rmse: 2.67253\tvalid_1's rmse: 2.72918\n",
      "[1590]\ttraining's rmse: 2.6688\tvalid_1's rmse: 2.7256\n",
      "[1600]\ttraining's rmse: 2.66478\tvalid_1's rmse: 2.72175\n",
      "[1610]\ttraining's rmse: 2.66179\tvalid_1's rmse: 2.71881\n",
      "[1620]\ttraining's rmse: 2.65767\tvalid_1's rmse: 2.71488\n",
      "[1630]\ttraining's rmse: 2.65383\tvalid_1's rmse: 2.71119\n",
      "[1640]\ttraining's rmse: 2.65005\tvalid_1's rmse: 2.70749\n",
      "[1650]\ttraining's rmse: 2.64498\tvalid_1's rmse: 2.7025\n",
      "[1660]\ttraining's rmse: 2.64082\tvalid_1's rmse: 2.6983\n",
      "[1670]\ttraining's rmse: 2.63512\tvalid_1's rmse: 2.69284\n",
      "[1680]\ttraining's rmse: 2.63141\tvalid_1's rmse: 2.68956\n",
      "[1690]\ttraining's rmse: 2.62783\tvalid_1's rmse: 2.68599\n",
      "[1700]\ttraining's rmse: 2.62421\tvalid_1's rmse: 2.68235\n",
      "[1710]\ttraining's rmse: 2.62138\tvalid_1's rmse: 2.67969\n",
      "[1720]\ttraining's rmse: 2.61738\tvalid_1's rmse: 2.67583\n",
      "[1730]\ttraining's rmse: 2.6136\tvalid_1's rmse: 2.67205\n",
      "[1740]\ttraining's rmse: 2.61088\tvalid_1's rmse: 2.6695\n",
      "[1750]\ttraining's rmse: 2.60898\tvalid_1's rmse: 2.66779\n",
      "[1760]\ttraining's rmse: 2.60745\tvalid_1's rmse: 2.66628\n",
      "[1770]\ttraining's rmse: 2.60189\tvalid_1's rmse: 2.66107\n",
      "[1780]\ttraining's rmse: 2.5991\tvalid_1's rmse: 2.65878\n",
      "[1790]\ttraining's rmse: 2.59599\tvalid_1's rmse: 2.65567\n",
      "[1800]\ttraining's rmse: 2.5936\tvalid_1's rmse: 2.65384\n",
      "[1810]\ttraining's rmse: 2.58769\tvalid_1's rmse: 2.64796\n",
      "[1820]\ttraining's rmse: 2.58579\tvalid_1's rmse: 2.64618\n",
      "[1830]\ttraining's rmse: 2.58287\tvalid_1's rmse: 2.64356\n",
      "[1840]\ttraining's rmse: 2.57701\tvalid_1's rmse: 2.63798\n",
      "[1850]\ttraining's rmse: 2.57319\tvalid_1's rmse: 2.63421\n",
      "[1860]\ttraining's rmse: 2.57058\tvalid_1's rmse: 2.63166\n",
      "[1870]\ttraining's rmse: 2.56644\tvalid_1's rmse: 2.62783\n",
      "[1880]\ttraining's rmse: 2.56257\tvalid_1's rmse: 2.62389\n",
      "[1890]\ttraining's rmse: 2.56105\tvalid_1's rmse: 2.62256\n",
      "[1900]\ttraining's rmse: 2.55759\tvalid_1's rmse: 2.61946\n",
      "[1910]\ttraining's rmse: 2.5552\tvalid_1's rmse: 2.61749\n",
      "[1920]\ttraining's rmse: 2.55301\tvalid_1's rmse: 2.61521\n",
      "[1930]\ttraining's rmse: 2.54843\tvalid_1's rmse: 2.61049\n",
      "[1940]\ttraining's rmse: 2.54597\tvalid_1's rmse: 2.60823\n",
      "[1950]\ttraining's rmse: 2.54024\tvalid_1's rmse: 2.6029\n",
      "[1960]\ttraining's rmse: 2.53872\tvalid_1's rmse: 2.60134\n",
      "[1970]\ttraining's rmse: 2.53479\tvalid_1's rmse: 2.5976\n",
      "[1980]\ttraining's rmse: 2.53134\tvalid_1's rmse: 2.59425\n",
      "[1990]\ttraining's rmse: 2.52607\tvalid_1's rmse: 2.58907\n",
      "[2000]\ttraining's rmse: 2.52403\tvalid_1's rmse: 2.58709\n",
      "[2010]\ttraining's rmse: 2.5205\tvalid_1's rmse: 2.5838\n",
      "[2020]\ttraining's rmse: 2.51622\tvalid_1's rmse: 2.57966\n",
      "[2030]\ttraining's rmse: 2.51302\tvalid_1's rmse: 2.57703\n",
      "[2040]\ttraining's rmse: 2.50929\tvalid_1's rmse: 2.57355\n",
      "[2050]\ttraining's rmse: 2.50473\tvalid_1's rmse: 2.56905\n",
      "[2060]\ttraining's rmse: 2.50179\tvalid_1's rmse: 2.56642\n",
      "[2070]\ttraining's rmse: 2.49869\tvalid_1's rmse: 2.56352\n",
      "[2080]\ttraining's rmse: 2.49577\tvalid_1's rmse: 2.56077\n",
      "[2090]\ttraining's rmse: 2.4934\tvalid_1's rmse: 2.5586\n",
      "[2100]\ttraining's rmse: 2.49093\tvalid_1's rmse: 2.55626\n",
      "[2110]\ttraining's rmse: 2.48834\tvalid_1's rmse: 2.55373\n",
      "[2120]\ttraining's rmse: 2.48627\tvalid_1's rmse: 2.5518\n",
      "[2130]\ttraining's rmse: 2.48373\tvalid_1's rmse: 2.54949\n",
      "[2140]\ttraining's rmse: 2.48061\tvalid_1's rmse: 2.54639\n",
      "[2150]\ttraining's rmse: 2.47866\tvalid_1's rmse: 2.54443\n",
      "[2160]\ttraining's rmse: 2.47582\tvalid_1's rmse: 2.54162\n",
      "[2170]\ttraining's rmse: 2.47336\tvalid_1's rmse: 2.53923\n",
      "[2180]\ttraining's rmse: 2.47209\tvalid_1's rmse: 2.53824\n",
      "[2190]\ttraining's rmse: 2.46911\tvalid_1's rmse: 2.53549\n",
      "[2200]\ttraining's rmse: 2.46634\tvalid_1's rmse: 2.53284\n",
      "[2210]\ttraining's rmse: 2.46391\tvalid_1's rmse: 2.53044\n",
      "[2220]\ttraining's rmse: 2.46211\tvalid_1's rmse: 2.52888\n",
      "[2230]\ttraining's rmse: 2.45813\tvalid_1's rmse: 2.52513\n",
      "[2240]\ttraining's rmse: 2.45543\tvalid_1's rmse: 2.52282\n",
      "[2250]\ttraining's rmse: 2.45243\tvalid_1's rmse: 2.52007\n",
      "[2260]\ttraining's rmse: 2.44981\tvalid_1's rmse: 2.5175\n",
      "[2270]\ttraining's rmse: 2.44652\tvalid_1's rmse: 2.51441\n",
      "[2280]\ttraining's rmse: 2.44323\tvalid_1's rmse: 2.51153\n",
      "[2290]\ttraining's rmse: 2.43987\tvalid_1's rmse: 2.50818\n",
      "[2300]\ttraining's rmse: 2.43617\tvalid_1's rmse: 2.50468\n",
      "[2310]\ttraining's rmse: 2.43386\tvalid_1's rmse: 2.50257\n",
      "[2320]\ttraining's rmse: 2.43114\tvalid_1's rmse: 2.49986\n",
      "[2330]\ttraining's rmse: 2.42921\tvalid_1's rmse: 2.49794\n",
      "[2340]\ttraining's rmse: 2.42653\tvalid_1's rmse: 2.49546\n",
      "[2350]\ttraining's rmse: 2.42469\tvalid_1's rmse: 2.49371\n",
      "[2360]\ttraining's rmse: 2.4216\tvalid_1's rmse: 2.49096\n",
      "[2370]\ttraining's rmse: 2.42002\tvalid_1's rmse: 2.4894\n",
      "[2380]\ttraining's rmse: 2.41802\tvalid_1's rmse: 2.48799\n",
      "[2390]\ttraining's rmse: 2.41616\tvalid_1's rmse: 2.48642\n",
      "[2400]\ttraining's rmse: 2.41489\tvalid_1's rmse: 2.48542\n",
      "[2410]\ttraining's rmse: 2.41335\tvalid_1's rmse: 2.48405\n",
      "[2420]\ttraining's rmse: 2.40907\tvalid_1's rmse: 2.47989\n",
      "[2430]\ttraining's rmse: 2.40531\tvalid_1's rmse: 2.47641\n",
      "[2440]\ttraining's rmse: 2.40333\tvalid_1's rmse: 2.47459\n",
      "[2450]\ttraining's rmse: 2.40234\tvalid_1's rmse: 2.47343\n",
      "[2460]\ttraining's rmse: 2.40029\tvalid_1's rmse: 2.47158\n",
      "[2470]\ttraining's rmse: 2.39734\tvalid_1's rmse: 2.469\n",
      "[2480]\ttraining's rmse: 2.39437\tvalid_1's rmse: 2.46638\n",
      "[2490]\ttraining's rmse: 2.39103\tvalid_1's rmse: 2.4637\n",
      "[2500]\ttraining's rmse: 2.3875\tvalid_1's rmse: 2.46041\n",
      "[2510]\ttraining's rmse: 2.38437\tvalid_1's rmse: 2.45777\n",
      "[2520]\ttraining's rmse: 2.38199\tvalid_1's rmse: 2.45557\n",
      "[2530]\ttraining's rmse: 2.37921\tvalid_1's rmse: 2.45298\n",
      "[2540]\ttraining's rmse: 2.37766\tvalid_1's rmse: 2.45159\n",
      "[2550]\ttraining's rmse: 2.37599\tvalid_1's rmse: 2.45014\n",
      "[2560]\ttraining's rmse: 2.37375\tvalid_1's rmse: 2.44815\n",
      "[2570]\ttraining's rmse: 2.37114\tvalid_1's rmse: 2.44582\n",
      "[2580]\ttraining's rmse: 2.37009\tvalid_1's rmse: 2.44497\n",
      "[2590]\ttraining's rmse: 2.36832\tvalid_1's rmse: 2.44333\n",
      "[2600]\ttraining's rmse: 2.36513\tvalid_1's rmse: 2.44021\n",
      "[2610]\ttraining's rmse: 2.36392\tvalid_1's rmse: 2.43926\n",
      "[2620]\ttraining's rmse: 2.36197\tvalid_1's rmse: 2.43743\n",
      "[2630]\ttraining's rmse: 2.35964\tvalid_1's rmse: 2.43531\n",
      "[2640]\ttraining's rmse: 2.35885\tvalid_1's rmse: 2.43453\n",
      "[2650]\ttraining's rmse: 2.35804\tvalid_1's rmse: 2.43393\n",
      "[2660]\ttraining's rmse: 2.35624\tvalid_1's rmse: 2.43225\n",
      "[2670]\ttraining's rmse: 2.35434\tvalid_1's rmse: 2.43047\n",
      "[2680]\ttraining's rmse: 2.35336\tvalid_1's rmse: 2.42949\n",
      "[2690]\ttraining's rmse: 2.35128\tvalid_1's rmse: 2.42744\n",
      "[2700]\ttraining's rmse: 2.34988\tvalid_1's rmse: 2.42602\n",
      "[2710]\ttraining's rmse: 2.34801\tvalid_1's rmse: 2.42426\n",
      "[2720]\ttraining's rmse: 2.34647\tvalid_1's rmse: 2.42294\n",
      "[2730]\ttraining's rmse: 2.34412\tvalid_1's rmse: 2.42086\n",
      "[2740]\ttraining's rmse: 2.34224\tvalid_1's rmse: 2.4191\n",
      "[2750]\ttraining's rmse: 2.34024\tvalid_1's rmse: 2.41727\n",
      "[2760]\ttraining's rmse: 2.33816\tvalid_1's rmse: 2.41546\n",
      "[2770]\ttraining's rmse: 2.33554\tvalid_1's rmse: 2.4129\n",
      "[2780]\ttraining's rmse: 2.33246\tvalid_1's rmse: 2.40989\n",
      "[2790]\ttraining's rmse: 2.33023\tvalid_1's rmse: 2.40793\n",
      "[2800]\ttraining's rmse: 2.3279\tvalid_1's rmse: 2.40569\n",
      "[2810]\ttraining's rmse: 2.3265\tvalid_1's rmse: 2.40436\n",
      "[2820]\ttraining's rmse: 2.32476\tvalid_1's rmse: 2.40316\n",
      "[2830]\ttraining's rmse: 2.32215\tvalid_1's rmse: 2.40066\n",
      "[2840]\ttraining's rmse: 2.32083\tvalid_1's rmse: 2.39938\n",
      "[2850]\ttraining's rmse: 2.31852\tvalid_1's rmse: 2.39716\n",
      "[2860]\ttraining's rmse: 2.31615\tvalid_1's rmse: 2.395\n",
      "[2870]\ttraining's rmse: 2.31371\tvalid_1's rmse: 2.39248\n",
      "[2880]\ttraining's rmse: 2.31221\tvalid_1's rmse: 2.39136\n",
      "[2890]\ttraining's rmse: 2.31056\tvalid_1's rmse: 2.39022\n",
      "[2900]\ttraining's rmse: 2.30857\tvalid_1's rmse: 2.38853\n",
      "[2910]\ttraining's rmse: 2.30554\tvalid_1's rmse: 2.38557\n",
      "[2920]\ttraining's rmse: 2.30327\tvalid_1's rmse: 2.38346\n",
      "[2930]\ttraining's rmse: 2.30047\tvalid_1's rmse: 2.38078\n",
      "[2940]\ttraining's rmse: 2.29952\tvalid_1's rmse: 2.37989\n",
      "[2950]\ttraining's rmse: 2.29799\tvalid_1's rmse: 2.37848\n",
      "[2960]\ttraining's rmse: 2.29673\tvalid_1's rmse: 2.37736\n",
      "[2970]\ttraining's rmse: 2.29513\tvalid_1's rmse: 2.37584\n",
      "[2980]\ttraining's rmse: 2.29342\tvalid_1's rmse: 2.37435\n",
      "[2990]\ttraining's rmse: 2.29098\tvalid_1's rmse: 2.37211\n",
      "[3000]\ttraining's rmse: 2.29004\tvalid_1's rmse: 2.3714\n",
      "[3010]\ttraining's rmse: 2.28909\tvalid_1's rmse: 2.37052\n",
      "[3020]\ttraining's rmse: 2.28602\tvalid_1's rmse: 2.36754\n",
      "[3030]\ttraining's rmse: 2.28456\tvalid_1's rmse: 2.36659\n",
      "[3040]\ttraining's rmse: 2.28151\tvalid_1's rmse: 2.36358\n",
      "[3050]\ttraining's rmse: 2.27962\tvalid_1's rmse: 2.36178\n",
      "[3060]\ttraining's rmse: 2.27906\tvalid_1's rmse: 2.36136\n",
      "[3070]\ttraining's rmse: 2.27758\tvalid_1's rmse: 2.36007\n",
      "[3080]\ttraining's rmse: 2.2763\tvalid_1's rmse: 2.35882\n",
      "[3090]\ttraining's rmse: 2.274\tvalid_1's rmse: 2.35657\n",
      "[3100]\ttraining's rmse: 2.27232\tvalid_1's rmse: 2.35512\n",
      "[3110]\ttraining's rmse: 2.27113\tvalid_1's rmse: 2.35405\n",
      "[3120]\ttraining's rmse: 2.26982\tvalid_1's rmse: 2.35294\n",
      "[3130]\ttraining's rmse: 2.26876\tvalid_1's rmse: 2.35237\n",
      "[3140]\ttraining's rmse: 2.26761\tvalid_1's rmse: 2.35132\n",
      "[3150]\ttraining's rmse: 2.26627\tvalid_1's rmse: 2.35005\n",
      "[3160]\ttraining's rmse: 2.2644\tvalid_1's rmse: 2.34844\n",
      "[3170]\ttraining's rmse: 2.26363\tvalid_1's rmse: 2.34796\n",
      "[3180]\ttraining's rmse: 2.26161\tvalid_1's rmse: 2.34612\n",
      "[3190]\ttraining's rmse: 2.26026\tvalid_1's rmse: 2.34505\n",
      "[3200]\ttraining's rmse: 2.25914\tvalid_1's rmse: 2.34402\n",
      "[3210]\ttraining's rmse: 2.25785\tvalid_1's rmse: 2.34295\n",
      "[3220]\ttraining's rmse: 2.25487\tvalid_1's rmse: 2.34002\n",
      "[3230]\ttraining's rmse: 2.2526\tvalid_1's rmse: 2.33774\n",
      "[3240]\ttraining's rmse: 2.25123\tvalid_1's rmse: 2.33651\n",
      "[3250]\ttraining's rmse: 2.25033\tvalid_1's rmse: 2.33547\n",
      "[3260]\ttraining's rmse: 2.24892\tvalid_1's rmse: 2.33413\n",
      "[3270]\ttraining's rmse: 2.24689\tvalid_1's rmse: 2.33197\n",
      "[3280]\ttraining's rmse: 2.24513\tvalid_1's rmse: 2.33032\n",
      "[3290]\ttraining's rmse: 2.24443\tvalid_1's rmse: 2.32965\n",
      "[3300]\ttraining's rmse: 2.24244\tvalid_1's rmse: 2.32769\n",
      "[3310]\ttraining's rmse: 2.2409\tvalid_1's rmse: 2.32638\n",
      "[3320]\ttraining's rmse: 2.23996\tvalid_1's rmse: 2.3258\n",
      "[3330]\ttraining's rmse: 2.2386\tvalid_1's rmse: 2.32458\n",
      "[3340]\ttraining's rmse: 2.23735\tvalid_1's rmse: 2.32349\n",
      "[3350]\ttraining's rmse: 2.23509\tvalid_1's rmse: 2.3213\n",
      "[3360]\ttraining's rmse: 2.23329\tvalid_1's rmse: 2.31938\n",
      "[3370]\ttraining's rmse: 2.23119\tvalid_1's rmse: 2.31739\n",
      "[3380]\ttraining's rmse: 2.22843\tvalid_1's rmse: 2.31506\n",
      "[3390]\ttraining's rmse: 2.22711\tvalid_1's rmse: 2.31397\n",
      "[3400]\ttraining's rmse: 2.22615\tvalid_1's rmse: 2.31298\n",
      "[3410]\ttraining's rmse: 2.22501\tvalid_1's rmse: 2.31227\n",
      "[3420]\ttraining's rmse: 2.2241\tvalid_1's rmse: 2.31157\n",
      "[3430]\ttraining's rmse: 2.22327\tvalid_1's rmse: 2.31086\n",
      "[3440]\ttraining's rmse: 2.22111\tvalid_1's rmse: 2.30871\n",
      "[3450]\ttraining's rmse: 2.21913\tvalid_1's rmse: 2.30667\n",
      "[3460]\ttraining's rmse: 2.21702\tvalid_1's rmse: 2.30461\n",
      "[3470]\ttraining's rmse: 2.21621\tvalid_1's rmse: 2.30385\n",
      "[3480]\ttraining's rmse: 2.21558\tvalid_1's rmse: 2.30335\n",
      "[3490]\ttraining's rmse: 2.21464\tvalid_1's rmse: 2.30282\n",
      "[3500]\ttraining's rmse: 2.21326\tvalid_1's rmse: 2.30149\n",
      "[3510]\ttraining's rmse: 2.21256\tvalid_1's rmse: 2.301\n",
      "[3520]\ttraining's rmse: 2.21156\tvalid_1's rmse: 2.30019\n",
      "[3530]\ttraining's rmse: 2.20985\tvalid_1's rmse: 2.29874\n",
      "[3540]\ttraining's rmse: 2.20774\tvalid_1's rmse: 2.29688\n",
      "[3550]\ttraining's rmse: 2.20564\tvalid_1's rmse: 2.29491\n",
      "[3560]\ttraining's rmse: 2.20484\tvalid_1's rmse: 2.2943\n",
      "[3570]\ttraining's rmse: 2.20382\tvalid_1's rmse: 2.29333\n",
      "[3580]\ttraining's rmse: 2.20067\tvalid_1's rmse: 2.29024\n",
      "[3590]\ttraining's rmse: 2.19938\tvalid_1's rmse: 2.28898\n",
      "[3600]\ttraining's rmse: 2.19749\tvalid_1's rmse: 2.28723\n",
      "[3610]\ttraining's rmse: 2.19639\tvalid_1's rmse: 2.28646\n",
      "[3620]\ttraining's rmse: 2.19541\tvalid_1's rmse: 2.28564\n",
      "[3630]\ttraining's rmse: 2.19347\tvalid_1's rmse: 2.28384\n",
      "[3640]\ttraining's rmse: 2.19276\tvalid_1's rmse: 2.28331\n",
      "[3650]\ttraining's rmse: 2.19135\tvalid_1's rmse: 2.28203\n",
      "[3660]\ttraining's rmse: 2.18984\tvalid_1's rmse: 2.28051\n",
      "[3670]\ttraining's rmse: 2.18901\tvalid_1's rmse: 2.27999\n",
      "[3680]\ttraining's rmse: 2.1861\tvalid_1's rmse: 2.27711\n",
      "[3690]\ttraining's rmse: 2.18514\tvalid_1's rmse: 2.27622\n",
      "[3700]\ttraining's rmse: 2.18304\tvalid_1's rmse: 2.27441\n",
      "[3710]\ttraining's rmse: 2.18203\tvalid_1's rmse: 2.27363\n",
      "[3720]\ttraining's rmse: 2.18111\tvalid_1's rmse: 2.27301\n",
      "[3730]\ttraining's rmse: 2.17885\tvalid_1's rmse: 2.27069\n",
      "[3740]\ttraining's rmse: 2.17686\tvalid_1's rmse: 2.26872\n",
      "[3750]\ttraining's rmse: 2.17605\tvalid_1's rmse: 2.26815\n",
      "[3760]\ttraining's rmse: 2.17552\tvalid_1's rmse: 2.2678\n",
      "[3770]\ttraining's rmse: 2.17476\tvalid_1's rmse: 2.26715\n",
      "[3780]\ttraining's rmse: 2.17314\tvalid_1's rmse: 2.26569\n",
      "[3790]\ttraining's rmse: 2.17148\tvalid_1's rmse: 2.26409\n",
      "[3800]\ttraining's rmse: 2.17055\tvalid_1's rmse: 2.26342\n",
      "[3810]\ttraining's rmse: 2.1692\tvalid_1's rmse: 2.26218\n",
      "[3820]\ttraining's rmse: 2.16673\tvalid_1's rmse: 2.26008\n",
      "[3830]\ttraining's rmse: 2.16548\tvalid_1's rmse: 2.25889\n",
      "[3840]\ttraining's rmse: 2.1642\tvalid_1's rmse: 2.25785\n",
      "[3850]\ttraining's rmse: 2.16357\tvalid_1's rmse: 2.25733\n",
      "[3860]\ttraining's rmse: 2.16224\tvalid_1's rmse: 2.25621\n",
      "[3870]\ttraining's rmse: 2.1614\tvalid_1's rmse: 2.2556\n",
      "[3880]\ttraining's rmse: 2.16037\tvalid_1's rmse: 2.25474\n",
      "[3890]\ttraining's rmse: 2.15873\tvalid_1's rmse: 2.2532\n",
      "[3900]\ttraining's rmse: 2.15763\tvalid_1's rmse: 2.25225\n",
      "[3910]\ttraining's rmse: 2.15606\tvalid_1's rmse: 2.25077\n",
      "[3920]\ttraining's rmse: 2.1538\tvalid_1's rmse: 2.24864\n",
      "[3930]\ttraining's rmse: 2.15234\tvalid_1's rmse: 2.24747\n",
      "[3940]\ttraining's rmse: 2.1509\tvalid_1's rmse: 2.24602\n",
      "[3950]\ttraining's rmse: 2.14972\tvalid_1's rmse: 2.24479\n",
      "[3960]\ttraining's rmse: 2.14874\tvalid_1's rmse: 2.24393\n",
      "[3970]\ttraining's rmse: 2.14747\tvalid_1's rmse: 2.24263\n",
      "[3980]\ttraining's rmse: 2.14575\tvalid_1's rmse: 2.24112\n",
      "[3990]\ttraining's rmse: 2.14421\tvalid_1's rmse: 2.23955\n",
      "[4000]\ttraining's rmse: 2.14355\tvalid_1's rmse: 2.23892\n",
      "[4010]\ttraining's rmse: 2.14323\tvalid_1's rmse: 2.23859\n",
      "[4020]\ttraining's rmse: 2.14161\tvalid_1's rmse: 2.23718\n",
      "[4030]\ttraining's rmse: 2.14027\tvalid_1's rmse: 2.23598\n",
      "[4040]\ttraining's rmse: 2.13946\tvalid_1's rmse: 2.23514\n",
      "[4050]\ttraining's rmse: 2.13813\tvalid_1's rmse: 2.23406\n",
      "[4060]\ttraining's rmse: 2.13725\tvalid_1's rmse: 2.23326\n",
      "[4070]\ttraining's rmse: 2.13688\tvalid_1's rmse: 2.23317\n",
      "[4080]\ttraining's rmse: 2.13487\tvalid_1's rmse: 2.23136\n",
      "[4090]\ttraining's rmse: 2.13368\tvalid_1's rmse: 2.23026\n",
      "[4100]\ttraining's rmse: 2.13227\tvalid_1's rmse: 2.22919\n",
      "[4110]\ttraining's rmse: 2.13179\tvalid_1's rmse: 2.22888\n",
      "[4120]\ttraining's rmse: 2.13058\tvalid_1's rmse: 2.22763\n",
      "[4130]\ttraining's rmse: 2.12928\tvalid_1's rmse: 2.22652\n",
      "[4140]\ttraining's rmse: 2.12801\tvalid_1's rmse: 2.22515\n",
      "[4150]\ttraining's rmse: 2.12749\tvalid_1's rmse: 2.22471\n",
      "[4160]\ttraining's rmse: 2.12638\tvalid_1's rmse: 2.22359\n",
      "[4170]\ttraining's rmse: 2.12566\tvalid_1's rmse: 2.22313\n",
      "[4180]\ttraining's rmse: 2.12429\tvalid_1's rmse: 2.22208\n",
      "[4190]\ttraining's rmse: 2.12329\tvalid_1's rmse: 2.22152\n",
      "[4200]\ttraining's rmse: 2.12129\tvalid_1's rmse: 2.21974\n",
      "[4210]\ttraining's rmse: 2.1194\tvalid_1's rmse: 2.21809\n",
      "[4220]\ttraining's rmse: 2.11854\tvalid_1's rmse: 2.21737\n",
      "[4230]\ttraining's rmse: 2.11741\tvalid_1's rmse: 2.21642\n",
      "[4240]\ttraining's rmse: 2.11635\tvalid_1's rmse: 2.21555\n",
      "[4250]\ttraining's rmse: 2.11469\tvalid_1's rmse: 2.21393\n",
      "[4260]\ttraining's rmse: 2.11264\tvalid_1's rmse: 2.21236\n",
      "[4270]\ttraining's rmse: 2.11137\tvalid_1's rmse: 2.21125\n",
      "[4280]\ttraining's rmse: 2.11002\tvalid_1's rmse: 2.20997\n",
      "[4290]\ttraining's rmse: 2.10734\tvalid_1's rmse: 2.20737\n",
      "[4300]\ttraining's rmse: 2.10663\tvalid_1's rmse: 2.20672\n",
      "[4310]\ttraining's rmse: 2.10596\tvalid_1's rmse: 2.2061\n",
      "[4320]\ttraining's rmse: 2.10532\tvalid_1's rmse: 2.2057\n",
      "[4330]\ttraining's rmse: 2.10461\tvalid_1's rmse: 2.20513\n",
      "[4340]\ttraining's rmse: 2.10402\tvalid_1's rmse: 2.20451\n",
      "[4350]\ttraining's rmse: 2.10269\tvalid_1's rmse: 2.20322\n",
      "[4360]\ttraining's rmse: 2.10155\tvalid_1's rmse: 2.20233\n",
      "[4370]\ttraining's rmse: 2.09963\tvalid_1's rmse: 2.20058\n",
      "[4380]\ttraining's rmse: 2.09879\tvalid_1's rmse: 2.20002\n",
      "[4390]\ttraining's rmse: 2.09729\tvalid_1's rmse: 2.19877\n",
      "[4400]\ttraining's rmse: 2.09548\tvalid_1's rmse: 2.19711\n",
      "[4410]\ttraining's rmse: 2.09447\tvalid_1's rmse: 2.19623\n",
      "[4420]\ttraining's rmse: 2.09353\tvalid_1's rmse: 2.19541\n",
      "[4430]\ttraining's rmse: 2.09259\tvalid_1's rmse: 2.19445\n",
      "[4440]\ttraining's rmse: 2.09242\tvalid_1's rmse: 2.19441\n",
      "[4450]\ttraining's rmse: 2.09118\tvalid_1's rmse: 2.1932\n",
      "[4460]\ttraining's rmse: 2.09002\tvalid_1's rmse: 2.19229\n",
      "[4470]\ttraining's rmse: 2.08811\tvalid_1's rmse: 2.19049\n",
      "[4480]\ttraining's rmse: 2.08779\tvalid_1's rmse: 2.19024\n",
      "[4490]\ttraining's rmse: 2.08725\tvalid_1's rmse: 2.18988\n",
      "[4500]\ttraining's rmse: 2.08591\tvalid_1's rmse: 2.18868\n",
      "[4510]\ttraining's rmse: 2.0845\tvalid_1's rmse: 2.18745\n",
      "[4520]\ttraining's rmse: 2.0836\tvalid_1's rmse: 2.18679\n",
      "[4530]\ttraining's rmse: 2.08283\tvalid_1's rmse: 2.1861\n",
      "[4540]\ttraining's rmse: 2.08185\tvalid_1's rmse: 2.18533\n",
      "[4550]\ttraining's rmse: 2.08114\tvalid_1's rmse: 2.18464\n",
      "[4560]\ttraining's rmse: 2.08047\tvalid_1's rmse: 2.18415\n",
      "[4570]\ttraining's rmse: 2.07972\tvalid_1's rmse: 2.18364\n",
      "[4580]\ttraining's rmse: 2.07906\tvalid_1's rmse: 2.18302\n",
      "[4590]\ttraining's rmse: 2.07841\tvalid_1's rmse: 2.18265\n",
      "[4600]\ttraining's rmse: 2.07685\tvalid_1's rmse: 2.18115\n",
      "[4610]\ttraining's rmse: 2.07559\tvalid_1's rmse: 2.18016\n",
      "[4620]\ttraining's rmse: 2.0741\tvalid_1's rmse: 2.17885\n",
      "[4630]\ttraining's rmse: 2.07317\tvalid_1's rmse: 2.17802\n",
      "[4640]\ttraining's rmse: 2.0717\tvalid_1's rmse: 2.17686\n",
      "[4650]\ttraining's rmse: 2.07066\tvalid_1's rmse: 2.17604\n",
      "[4660]\ttraining's rmse: 2.07013\tvalid_1's rmse: 2.17572\n",
      "[4670]\ttraining's rmse: 2.06923\tvalid_1's rmse: 2.17492\n",
      "[4680]\ttraining's rmse: 2.06869\tvalid_1's rmse: 2.17452\n",
      "[4690]\ttraining's rmse: 2.06771\tvalid_1's rmse: 2.17363\n",
      "[4700]\ttraining's rmse: 2.06645\tvalid_1's rmse: 2.17256\n",
      "[4710]\ttraining's rmse: 2.06548\tvalid_1's rmse: 2.17169\n",
      "[4720]\ttraining's rmse: 2.06487\tvalid_1's rmse: 2.17126\n",
      "[4730]\ttraining's rmse: 2.06405\tvalid_1's rmse: 2.1706\n",
      "[4740]\ttraining's rmse: 2.0634\tvalid_1's rmse: 2.17004\n",
      "[4750]\ttraining's rmse: 2.06226\tvalid_1's rmse: 2.16887\n",
      "[4760]\ttraining's rmse: 2.061\tvalid_1's rmse: 2.1677\n",
      "[4770]\ttraining's rmse: 2.06\tvalid_1's rmse: 2.1669\n",
      "[4780]\ttraining's rmse: 2.05923\tvalid_1's rmse: 2.16634\n",
      "[4790]\ttraining's rmse: 2.05763\tvalid_1's rmse: 2.16488\n",
      "[4800]\ttraining's rmse: 2.05683\tvalid_1's rmse: 2.16428\n",
      "[4810]\ttraining's rmse: 2.05625\tvalid_1's rmse: 2.16379\n",
      "[4820]\ttraining's rmse: 2.05556\tvalid_1's rmse: 2.16325\n",
      "[4830]\ttraining's rmse: 2.05392\tvalid_1's rmse: 2.16168\n",
      "[4840]\ttraining's rmse: 2.05265\tvalid_1's rmse: 2.16055\n",
      "[4850]\ttraining's rmse: 2.05203\tvalid_1's rmse: 2.15993\n",
      "[4860]\ttraining's rmse: 2.05095\tvalid_1's rmse: 2.15905\n",
      "[4870]\ttraining's rmse: 2.05024\tvalid_1's rmse: 2.1585\n",
      "[4880]\ttraining's rmse: 2.04899\tvalid_1's rmse: 2.15747\n",
      "[4890]\ttraining's rmse: 2.04848\tvalid_1's rmse: 2.15729\n",
      "[4900]\ttraining's rmse: 2.04722\tvalid_1's rmse: 2.15618\n",
      "[4910]\ttraining's rmse: 2.04655\tvalid_1's rmse: 2.15552\n",
      "[4920]\ttraining's rmse: 2.04582\tvalid_1's rmse: 2.15503\n",
      "[4930]\ttraining's rmse: 2.04552\tvalid_1's rmse: 2.15475\n",
      "[4940]\ttraining's rmse: 2.04428\tvalid_1's rmse: 2.15381\n",
      "[4950]\ttraining's rmse: 2.04341\tvalid_1's rmse: 2.15306\n",
      "[4960]\ttraining's rmse: 2.04238\tvalid_1's rmse: 2.15226\n",
      "[4970]\ttraining's rmse: 2.04167\tvalid_1's rmse: 2.15149\n",
      "[4980]\ttraining's rmse: 2.04083\tvalid_1's rmse: 2.15084\n",
      "[4990]\ttraining's rmse: 2.0402\tvalid_1's rmse: 2.15038\n",
      "[5000]\ttraining's rmse: 2.03974\tvalid_1's rmse: 2.15007\n",
      "[5010]\ttraining's rmse: 2.03881\tvalid_1's rmse: 2.14938\n",
      "[5020]\ttraining's rmse: 2.03811\tvalid_1's rmse: 2.14869\n",
      "[5030]\ttraining's rmse: 2.03636\tvalid_1's rmse: 2.14709\n",
      "[5040]\ttraining's rmse: 2.03548\tvalid_1's rmse: 2.14649\n",
      "[5050]\ttraining's rmse: 2.03516\tvalid_1's rmse: 2.1463\n",
      "[5060]\ttraining's rmse: 2.03421\tvalid_1's rmse: 2.14536\n",
      "[5070]\ttraining's rmse: 2.03392\tvalid_1's rmse: 2.14514\n",
      "[5080]\ttraining's rmse: 2.03285\tvalid_1's rmse: 2.14416\n",
      "[5090]\ttraining's rmse: 2.03202\tvalid_1's rmse: 2.14353\n",
      "[5100]\ttraining's rmse: 2.03094\tvalid_1's rmse: 2.14248\n",
      "[5110]\ttraining's rmse: 2.0301\tvalid_1's rmse: 2.14189\n",
      "[5120]\ttraining's rmse: 2.0293\tvalid_1's rmse: 2.14116\n",
      "[5130]\ttraining's rmse: 2.02812\tvalid_1's rmse: 2.14005\n",
      "[5140]\ttraining's rmse: 2.02774\tvalid_1's rmse: 2.1399\n",
      "[5150]\ttraining's rmse: 2.02624\tvalid_1's rmse: 2.13848\n",
      "[5160]\ttraining's rmse: 2.02582\tvalid_1's rmse: 2.13832\n",
      "[5170]\ttraining's rmse: 2.02494\tvalid_1's rmse: 2.13758\n",
      "[5180]\ttraining's rmse: 2.02382\tvalid_1's rmse: 2.13678\n",
      "[5190]\ttraining's rmse: 2.0232\tvalid_1's rmse: 2.13642\n",
      "[5200]\ttraining's rmse: 2.02219\tvalid_1's rmse: 2.13561\n",
      "[5210]\ttraining's rmse: 2.02141\tvalid_1's rmse: 2.13489\n",
      "[5220]\ttraining's rmse: 2.02072\tvalid_1's rmse: 2.13425\n",
      "[5230]\ttraining's rmse: 2.01945\tvalid_1's rmse: 2.13323\n",
      "[5240]\ttraining's rmse: 2.0188\tvalid_1's rmse: 2.13272\n",
      "[5250]\ttraining's rmse: 2.01819\tvalid_1's rmse: 2.13233\n",
      "[5260]\ttraining's rmse: 2.01748\tvalid_1's rmse: 2.13174\n",
      "[5270]\ttraining's rmse: 2.01692\tvalid_1's rmse: 2.13118\n",
      "[5280]\ttraining's rmse: 2.01489\tvalid_1's rmse: 2.12919\n",
      "[5290]\ttraining's rmse: 2.01407\tvalid_1's rmse: 2.12868\n",
      "[5300]\ttraining's rmse: 2.01371\tvalid_1's rmse: 2.12839\n",
      "[5310]\ttraining's rmse: 2.01296\tvalid_1's rmse: 2.12793\n",
      "[5320]\ttraining's rmse: 2.01223\tvalid_1's rmse: 2.12719\n",
      "[5330]\ttraining's rmse: 2.01142\tvalid_1's rmse: 2.12637\n",
      "[5340]\ttraining's rmse: 2.01033\tvalid_1's rmse: 2.12547\n",
      "[5350]\ttraining's rmse: 2.00926\tvalid_1's rmse: 2.12448\n",
      "[5360]\ttraining's rmse: 2.00873\tvalid_1's rmse: 2.12409\n",
      "[5370]\ttraining's rmse: 2.00802\tvalid_1's rmse: 2.12343\n",
      "[5380]\ttraining's rmse: 2.00744\tvalid_1's rmse: 2.12296\n",
      "[5390]\ttraining's rmse: 2.00691\tvalid_1's rmse: 2.1224\n",
      "[5400]\ttraining's rmse: 2.00654\tvalid_1's rmse: 2.12224\n",
      "[5410]\ttraining's rmse: 2.00584\tvalid_1's rmse: 2.1217\n",
      "[5420]\ttraining's rmse: 2.00477\tvalid_1's rmse: 2.12068\n",
      "[5430]\ttraining's rmse: 2.00445\tvalid_1's rmse: 2.12042\n",
      "[5440]\ttraining's rmse: 2.00297\tvalid_1's rmse: 2.11912\n",
      "[5450]\ttraining's rmse: 2.00187\tvalid_1's rmse: 2.11809\n",
      "[5460]\ttraining's rmse: 2.00118\tvalid_1's rmse: 2.11759\n",
      "[5470]\ttraining's rmse: 2.00014\tvalid_1's rmse: 2.11672\n",
      "[5480]\ttraining's rmse: 1.99964\tvalid_1's rmse: 2.11628\n",
      "[5490]\ttraining's rmse: 1.99895\tvalid_1's rmse: 2.11585\n",
      "[5500]\ttraining's rmse: 1.99764\tvalid_1's rmse: 2.11472\n",
      "[5510]\ttraining's rmse: 1.99663\tvalid_1's rmse: 2.11377\n",
      "[5520]\ttraining's rmse: 1.99563\tvalid_1's rmse: 2.11272\n",
      "[5530]\ttraining's rmse: 1.9952\tvalid_1's rmse: 2.11243\n",
      "[5540]\ttraining's rmse: 1.99476\tvalid_1's rmse: 2.11204\n",
      "[5550]\ttraining's rmse: 1.99375\tvalid_1's rmse: 2.11111\n",
      "[5560]\ttraining's rmse: 1.99265\tvalid_1's rmse: 2.11017\n",
      "[5570]\ttraining's rmse: 1.99187\tvalid_1's rmse: 2.10956\n",
      "[5580]\ttraining's rmse: 1.99115\tvalid_1's rmse: 2.10895\n",
      "[5590]\ttraining's rmse: 1.99089\tvalid_1's rmse: 2.10872\n",
      "[5600]\ttraining's rmse: 1.99054\tvalid_1's rmse: 2.10863\n",
      "Early stopping, best iteration is:\n",
      "[5595]\ttraining's rmse: 1.99066\tvalid_1's rmse: 2.10859\n",
      "Predictions:\n",
      "[7 3 2 ... 3 4 4]\n",
      "RMSE: 0.9744489868421946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model after the final split, ensuring it's aware of all classes\n",
    "params = {\n",
    "    'objective': 'regression',  # For regression tasks\n",
    "    'metric': 'rmse',           # Use RMSE as the evaluation metric\n",
    "    'boosting_type': 'gbdt',    # Traditional Gradient Boosting Decision Tree\n",
    "    'num_leaves': 31,           # Number of leaves in trees\n",
    "    'learning_rate': 0.05,      # Learning rate\n",
    "    'feature_fraction': 0.9,    # Fraction of features to be used in each iteration\n",
    "    'bagging_fraction': 0.8,    # Fraction of data to be used for each iteration\n",
    "    'bagging_freq': 5,          # Perform bagging every 5 iterations\n",
    "    'verbose': 0,               # Don't print messages during training\n",
    "    'num_iterations': 20000,      # Number of boosting iterations\n",
    "    'early_stopping_rounds': 10 # Stop training if the validation score doesn't improve for 10 rounds\n",
    "}\n",
    "\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  valid_sets=[train_data, val_data],\n",
    "                  callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)])  # Print progress\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred_rounded = np.round(y_pred).astype(int)\n",
    "y_pred_clipped = np.clip(y_pred_rounded, 1, 20)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_clipped))\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_clipped)\n",
    "print(f'RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightgbm\\engine.py:204: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 6.65996\tvalid_1's rmse: 6.6786\n",
      "[20]\ttraining's rmse: 5.32921\tvalid_1's rmse: 5.34415\n",
      "[30]\ttraining's rmse: 4.72894\tvalid_1's rmse: 4.73932\n",
      "[40]\ttraining's rmse: 4.44301\tvalid_1's rmse: 4.45032\n",
      "[50]\ttraining's rmse: 4.29563\tvalid_1's rmse: 4.30076\n",
      "[60]\ttraining's rmse: 4.20042\tvalid_1's rmse: 4.20346\n",
      "[70]\ttraining's rmse: 4.12588\tvalid_1's rmse: 4.12838\n",
      "[80]\ttraining's rmse: 4.0702\tvalid_1's rmse: 4.07172\n",
      "[90]\ttraining's rmse: 4.01163\tvalid_1's rmse: 4.01381\n",
      "[100]\ttraining's rmse: 3.96205\tvalid_1's rmse: 3.96426\n",
      "[110]\ttraining's rmse: 3.91967\tvalid_1's rmse: 3.92201\n",
      "[120]\ttraining's rmse: 3.88409\tvalid_1's rmse: 3.88652\n",
      "[130]\ttraining's rmse: 3.85295\tvalid_1's rmse: 3.85499\n",
      "[140]\ttraining's rmse: 3.82419\tvalid_1's rmse: 3.8264\n",
      "[150]\ttraining's rmse: 3.79643\tvalid_1's rmse: 3.79927\n",
      "[160]\ttraining's rmse: 3.7738\tvalid_1's rmse: 3.7773\n",
      "[170]\ttraining's rmse: 3.74755\tvalid_1's rmse: 3.75186\n",
      "[180]\ttraining's rmse: 3.72222\tvalid_1's rmse: 3.72693\n",
      "[190]\ttraining's rmse: 3.69978\tvalid_1's rmse: 3.70428\n",
      "[200]\ttraining's rmse: 3.67367\tvalid_1's rmse: 3.67856\n",
      "[210]\ttraining's rmse: 3.6514\tvalid_1's rmse: 3.65685\n",
      "[220]\ttraining's rmse: 3.63439\tvalid_1's rmse: 3.63993\n",
      "[230]\ttraining's rmse: 3.61335\tvalid_1's rmse: 3.619\n",
      "[240]\ttraining's rmse: 3.59494\tvalid_1's rmse: 3.60149\n",
      "[250]\ttraining's rmse: 3.5766\tvalid_1's rmse: 3.58296\n",
      "[260]\ttraining's rmse: 3.55517\tvalid_1's rmse: 3.56105\n",
      "[270]\ttraining's rmse: 3.54428\tvalid_1's rmse: 3.55081\n",
      "[280]\ttraining's rmse: 3.52321\tvalid_1's rmse: 3.53027\n",
      "[290]\ttraining's rmse: 3.50745\tvalid_1's rmse: 3.51434\n",
      "[300]\ttraining's rmse: 3.49148\tvalid_1's rmse: 3.49888\n",
      "[310]\ttraining's rmse: 3.47811\tvalid_1's rmse: 3.48573\n",
      "[320]\ttraining's rmse: 3.46166\tvalid_1's rmse: 3.46981\n",
      "[330]\ttraining's rmse: 3.44751\tvalid_1's rmse: 3.45661\n",
      "[340]\ttraining's rmse: 3.43199\tvalid_1's rmse: 3.44211\n",
      "[350]\ttraining's rmse: 3.42086\tvalid_1's rmse: 3.4318\n",
      "[360]\ttraining's rmse: 3.40562\tvalid_1's rmse: 3.41657\n",
      "[370]\ttraining's rmse: 3.39344\tvalid_1's rmse: 3.40437\n",
      "[380]\ttraining's rmse: 3.38042\tvalid_1's rmse: 3.39147\n",
      "[390]\ttraining's rmse: 3.36531\tvalid_1's rmse: 3.37679\n",
      "[400]\ttraining's rmse: 3.35226\tvalid_1's rmse: 3.36372\n",
      "[410]\ttraining's rmse: 3.34011\tvalid_1's rmse: 3.3518\n",
      "[420]\ttraining's rmse: 3.331\tvalid_1's rmse: 3.34303\n",
      "[430]\ttraining's rmse: 3.31969\tvalid_1's rmse: 3.33162\n",
      "[440]\ttraining's rmse: 3.30976\tvalid_1's rmse: 3.32159\n",
      "[450]\ttraining's rmse: 3.29604\tvalid_1's rmse: 3.30816\n",
      "[460]\ttraining's rmse: 3.28986\tvalid_1's rmse: 3.30247\n",
      "[470]\ttraining's rmse: 3.27323\tvalid_1's rmse: 3.28631\n",
      "[480]\ttraining's rmse: 3.264\tvalid_1's rmse: 3.27726\n",
      "[490]\ttraining's rmse: 3.25438\tvalid_1's rmse: 3.26805\n",
      "[500]\ttraining's rmse: 3.24754\tvalid_1's rmse: 3.26191\n",
      "[510]\ttraining's rmse: 3.23331\tvalid_1's rmse: 3.24786\n",
      "[520]\ttraining's rmse: 3.22301\tvalid_1's rmse: 3.23797\n",
      "[530]\ttraining's rmse: 3.21654\tvalid_1's rmse: 3.2315\n",
      "[540]\ttraining's rmse: 3.20303\tvalid_1's rmse: 3.21837\n",
      "[550]\ttraining's rmse: 3.19511\tvalid_1's rmse: 3.211\n",
      "[560]\ttraining's rmse: 3.1809\tvalid_1's rmse: 3.19704\n",
      "[570]\ttraining's rmse: 3.17247\tvalid_1's rmse: 3.18897\n",
      "[580]\ttraining's rmse: 3.16442\tvalid_1's rmse: 3.18169\n",
      "[590]\ttraining's rmse: 3.15906\tvalid_1's rmse: 3.17647\n",
      "[600]\ttraining's rmse: 3.14805\tvalid_1's rmse: 3.16555\n",
      "[610]\ttraining's rmse: 3.13972\tvalid_1's rmse: 3.15726\n",
      "[620]\ttraining's rmse: 3.13349\tvalid_1's rmse: 3.15137\n",
      "[630]\ttraining's rmse: 3.12304\tvalid_1's rmse: 3.14162\n",
      "[640]\ttraining's rmse: 3.11104\tvalid_1's rmse: 3.12939\n",
      "[650]\ttraining's rmse: 3.10474\tvalid_1's rmse: 3.12361\n",
      "[660]\ttraining's rmse: 3.09993\tvalid_1's rmse: 3.11892\n",
      "[670]\ttraining's rmse: 3.09327\tvalid_1's rmse: 3.11255\n",
      "[680]\ttraining's rmse: 3.08552\tvalid_1's rmse: 3.10485\n",
      "[690]\ttraining's rmse: 3.07452\tvalid_1's rmse: 3.09449\n",
      "[700]\ttraining's rmse: 3.06723\tvalid_1's rmse: 3.08751\n",
      "[710]\ttraining's rmse: 3.05785\tvalid_1's rmse: 3.07879\n",
      "[720]\ttraining's rmse: 3.05204\tvalid_1's rmse: 3.07327\n",
      "[730]\ttraining's rmse: 3.04553\tvalid_1's rmse: 3.06697\n",
      "[740]\ttraining's rmse: 3.03765\tvalid_1's rmse: 3.05906\n",
      "[750]\ttraining's rmse: 3.03104\tvalid_1's rmse: 3.05268\n",
      "[760]\ttraining's rmse: 3.02437\tvalid_1's rmse: 3.04627\n",
      "[770]\ttraining's rmse: 3.01815\tvalid_1's rmse: 3.04055\n",
      "[780]\ttraining's rmse: 3.01049\tvalid_1's rmse: 3.03313\n",
      "[790]\ttraining's rmse: 3.00466\tvalid_1's rmse: 3.0276\n",
      "[800]\ttraining's rmse: 2.99863\tvalid_1's rmse: 3.02202\n",
      "[810]\ttraining's rmse: 2.99247\tvalid_1's rmse: 3.01605\n",
      "[820]\ttraining's rmse: 2.9844\tvalid_1's rmse: 3.008\n",
      "[830]\ttraining's rmse: 2.97503\tvalid_1's rmse: 2.99883\n",
      "[840]\ttraining's rmse: 2.96999\tvalid_1's rmse: 2.99401\n",
      "[850]\ttraining's rmse: 2.96197\tvalid_1's rmse: 2.98645\n",
      "[860]\ttraining's rmse: 2.95586\tvalid_1's rmse: 2.98076\n",
      "[870]\ttraining's rmse: 2.95092\tvalid_1's rmse: 2.97618\n",
      "[880]\ttraining's rmse: 2.94571\tvalid_1's rmse: 2.97137\n",
      "[890]\ttraining's rmse: 2.93881\tvalid_1's rmse: 2.96447\n",
      "[900]\ttraining's rmse: 2.93362\tvalid_1's rmse: 2.95969\n",
      "[910]\ttraining's rmse: 2.92585\tvalid_1's rmse: 2.95232\n",
      "[920]\ttraining's rmse: 2.91742\tvalid_1's rmse: 2.94406\n",
      "[930]\ttraining's rmse: 2.91408\tvalid_1's rmse: 2.94091\n",
      "[940]\ttraining's rmse: 2.90773\tvalid_1's rmse: 2.93506\n",
      "[950]\ttraining's rmse: 2.9026\tvalid_1's rmse: 2.92998\n",
      "[960]\ttraining's rmse: 2.89791\tvalid_1's rmse: 2.92568\n",
      "[970]\ttraining's rmse: 2.89045\tvalid_1's rmse: 2.91826\n",
      "[980]\ttraining's rmse: 2.88332\tvalid_1's rmse: 2.91125\n",
      "[990]\ttraining's rmse: 2.87816\tvalid_1's rmse: 2.90613\n",
      "[1000]\ttraining's rmse: 2.8727\tvalid_1's rmse: 2.90099\n",
      "[1010]\ttraining's rmse: 2.86527\tvalid_1's rmse: 2.89376\n",
      "[1020]\ttraining's rmse: 2.86227\tvalid_1's rmse: 2.89105\n",
      "[1030]\ttraining's rmse: 2.85912\tvalid_1's rmse: 2.88796\n",
      "[1040]\ttraining's rmse: 2.85503\tvalid_1's rmse: 2.88407\n",
      "[1050]\ttraining's rmse: 2.85165\tvalid_1's rmse: 2.88088\n",
      "[1060]\ttraining's rmse: 2.84707\tvalid_1's rmse: 2.87644\n",
      "[1070]\ttraining's rmse: 2.841\tvalid_1's rmse: 2.87095\n",
      "[1080]\ttraining's rmse: 2.83489\tvalid_1's rmse: 2.86557\n",
      "[1090]\ttraining's rmse: 2.83053\tvalid_1's rmse: 2.86131\n",
      "[1100]\ttraining's rmse: 2.82338\tvalid_1's rmse: 2.85427\n",
      "[1110]\ttraining's rmse: 2.81897\tvalid_1's rmse: 2.85024\n",
      "[1120]\ttraining's rmse: 2.81503\tvalid_1's rmse: 2.8468\n",
      "[1130]\ttraining's rmse: 2.81123\tvalid_1's rmse: 2.843\n",
      "[1140]\ttraining's rmse: 2.8076\tvalid_1's rmse: 2.83963\n",
      "[1150]\ttraining's rmse: 2.80219\tvalid_1's rmse: 2.83447\n",
      "[1160]\ttraining's rmse: 2.79674\tvalid_1's rmse: 2.8293\n",
      "[1170]\ttraining's rmse: 2.79329\tvalid_1's rmse: 2.82643\n",
      "[1180]\ttraining's rmse: 2.78848\tvalid_1's rmse: 2.82204\n",
      "[1190]\ttraining's rmse: 2.78128\tvalid_1's rmse: 2.81516\n",
      "[1200]\ttraining's rmse: 2.77506\tvalid_1's rmse: 2.80912\n",
      "[1210]\ttraining's rmse: 2.77195\tvalid_1's rmse: 2.80616\n",
      "[1220]\ttraining's rmse: 2.76658\tvalid_1's rmse: 2.80109\n",
      "[1230]\ttraining's rmse: 2.76287\tvalid_1's rmse: 2.79751\n",
      "[1240]\ttraining's rmse: 2.75781\tvalid_1's rmse: 2.79276\n",
      "[1250]\ttraining's rmse: 2.75379\tvalid_1's rmse: 2.78907\n",
      "[1260]\ttraining's rmse: 2.74941\tvalid_1's rmse: 2.78481\n",
      "[1270]\ttraining's rmse: 2.74676\tvalid_1's rmse: 2.78221\n",
      "[1280]\ttraining's rmse: 2.74342\tvalid_1's rmse: 2.77889\n",
      "[1290]\ttraining's rmse: 2.73984\tvalid_1's rmse: 2.7755\n",
      "[1300]\ttraining's rmse: 2.73328\tvalid_1's rmse: 2.7691\n",
      "[1310]\ttraining's rmse: 2.72934\tvalid_1's rmse: 2.76537\n",
      "[1320]\ttraining's rmse: 2.72499\tvalid_1's rmse: 2.76109\n",
      "[1330]\ttraining's rmse: 2.72094\tvalid_1's rmse: 2.75723\n",
      "[1340]\ttraining's rmse: 2.71573\tvalid_1's rmse: 2.752\n",
      "[1350]\ttraining's rmse: 2.71011\tvalid_1's rmse: 2.74667\n",
      "[1360]\ttraining's rmse: 2.70624\tvalid_1's rmse: 2.74303\n",
      "[1370]\ttraining's rmse: 2.70179\tvalid_1's rmse: 2.73886\n",
      "[1380]\ttraining's rmse: 2.69786\tvalid_1's rmse: 2.73513\n",
      "[1390]\ttraining's rmse: 2.69445\tvalid_1's rmse: 2.73205\n",
      "[1400]\ttraining's rmse: 2.6917\tvalid_1's rmse: 2.72926\n",
      "[1410]\ttraining's rmse: 2.68824\tvalid_1's rmse: 2.72603\n",
      "[1420]\ttraining's rmse: 2.68207\tvalid_1's rmse: 2.71994\n",
      "[1430]\ttraining's rmse: 2.67898\tvalid_1's rmse: 2.71702\n",
      "[1440]\ttraining's rmse: 2.6744\tvalid_1's rmse: 2.71277\n",
      "[1450]\ttraining's rmse: 2.67063\tvalid_1's rmse: 2.70921\n",
      "[1460]\ttraining's rmse: 2.66663\tvalid_1's rmse: 2.70534\n",
      "[1470]\ttraining's rmse: 2.66382\tvalid_1's rmse: 2.70258\n",
      "[1480]\ttraining's rmse: 2.65995\tvalid_1's rmse: 2.699\n",
      "[1490]\ttraining's rmse: 2.65635\tvalid_1's rmse: 2.69584\n",
      "[1500]\ttraining's rmse: 2.65383\tvalid_1's rmse: 2.69361\n",
      "[1510]\ttraining's rmse: 2.65151\tvalid_1's rmse: 2.69146\n",
      "[1520]\ttraining's rmse: 2.64928\tvalid_1's rmse: 2.68914\n",
      "[1530]\ttraining's rmse: 2.64592\tvalid_1's rmse: 2.68616\n",
      "[1540]\ttraining's rmse: 2.64098\tvalid_1's rmse: 2.68135\n",
      "[1550]\ttraining's rmse: 2.63839\tvalid_1's rmse: 2.67893\n",
      "[1560]\ttraining's rmse: 2.63459\tvalid_1's rmse: 2.67518\n",
      "[1570]\ttraining's rmse: 2.63171\tvalid_1's rmse: 2.67258\n",
      "[1580]\ttraining's rmse: 2.6261\tvalid_1's rmse: 2.66717\n",
      "[1590]\ttraining's rmse: 2.62388\tvalid_1's rmse: 2.66505\n",
      "[1600]\ttraining's rmse: 2.61987\tvalid_1's rmse: 2.66118\n",
      "[1610]\ttraining's rmse: 2.61597\tvalid_1's rmse: 2.65743\n",
      "[1620]\ttraining's rmse: 2.61293\tvalid_1's rmse: 2.65472\n",
      "[1630]\ttraining's rmse: 2.60787\tvalid_1's rmse: 2.64993\n",
      "[1640]\ttraining's rmse: 2.6057\tvalid_1's rmse: 2.64824\n",
      "[1650]\ttraining's rmse: 2.60179\tvalid_1's rmse: 2.64451\n",
      "[1660]\ttraining's rmse: 2.59806\tvalid_1's rmse: 2.6411\n",
      "[1670]\ttraining's rmse: 2.5951\tvalid_1's rmse: 2.6384\n",
      "[1680]\ttraining's rmse: 2.59224\tvalid_1's rmse: 2.63579\n",
      "[1690]\ttraining's rmse: 2.59091\tvalid_1's rmse: 2.63479\n",
      "[1700]\ttraining's rmse: 2.58611\tvalid_1's rmse: 2.63008\n",
      "[1710]\ttraining's rmse: 2.58278\tvalid_1's rmse: 2.62698\n",
      "[1720]\ttraining's rmse: 2.57993\tvalid_1's rmse: 2.62428\n",
      "[1730]\ttraining's rmse: 2.57595\tvalid_1's rmse: 2.62022\n",
      "[1740]\ttraining's rmse: 2.57333\tvalid_1's rmse: 2.61787\n",
      "[1750]\ttraining's rmse: 2.56869\tvalid_1's rmse: 2.61358\n",
      "[1760]\ttraining's rmse: 2.56637\tvalid_1's rmse: 2.61146\n",
      "[1770]\ttraining's rmse: 2.56183\tvalid_1's rmse: 2.60711\n",
      "[1780]\ttraining's rmse: 2.55973\tvalid_1's rmse: 2.60524\n",
      "[1790]\ttraining's rmse: 2.55615\tvalid_1's rmse: 2.60176\n",
      "[1800]\ttraining's rmse: 2.5538\tvalid_1's rmse: 2.59973\n",
      "[1810]\ttraining's rmse: 2.55152\tvalid_1's rmse: 2.59759\n",
      "[1820]\ttraining's rmse: 2.54841\tvalid_1's rmse: 2.59464\n",
      "[1830]\ttraining's rmse: 2.5454\tvalid_1's rmse: 2.59184\n",
      "[1840]\ttraining's rmse: 2.54275\tvalid_1's rmse: 2.58969\n",
      "[1850]\ttraining's rmse: 2.54031\tvalid_1's rmse: 2.58731\n",
      "[1860]\ttraining's rmse: 2.53768\tvalid_1's rmse: 2.58509\n",
      "[1870]\ttraining's rmse: 2.53434\tvalid_1's rmse: 2.5822\n",
      "[1880]\ttraining's rmse: 2.53182\tvalid_1's rmse: 2.5798\n",
      "[1890]\ttraining's rmse: 2.5299\tvalid_1's rmse: 2.57785\n",
      "[1900]\ttraining's rmse: 2.52617\tvalid_1's rmse: 2.5743\n",
      "[1910]\ttraining's rmse: 2.52372\tvalid_1's rmse: 2.57178\n",
      "[1920]\ttraining's rmse: 2.52236\tvalid_1's rmse: 2.57065\n",
      "[1930]\ttraining's rmse: 2.51984\tvalid_1's rmse: 2.56831\n",
      "[1940]\ttraining's rmse: 2.51825\tvalid_1's rmse: 2.56696\n",
      "[1950]\ttraining's rmse: 2.51367\tvalid_1's rmse: 2.56227\n",
      "[1960]\ttraining's rmse: 2.51144\tvalid_1's rmse: 2.56041\n",
      "[1970]\ttraining's rmse: 2.50834\tvalid_1's rmse: 2.55749\n",
      "[1980]\ttraining's rmse: 2.50628\tvalid_1's rmse: 2.55552\n",
      "[1990]\ttraining's rmse: 2.50199\tvalid_1's rmse: 2.55124\n",
      "[2000]\ttraining's rmse: 2.49754\tvalid_1's rmse: 2.54699\n",
      "[2010]\ttraining's rmse: 2.49399\tvalid_1's rmse: 2.54332\n",
      "[2020]\ttraining's rmse: 2.49142\tvalid_1's rmse: 2.54064\n",
      "[2030]\ttraining's rmse: 2.4879\tvalid_1's rmse: 2.53735\n",
      "[2040]\ttraining's rmse: 2.48512\tvalid_1's rmse: 2.53472\n",
      "[2050]\ttraining's rmse: 2.48124\tvalid_1's rmse: 2.53089\n",
      "[2060]\ttraining's rmse: 2.47976\tvalid_1's rmse: 2.52945\n",
      "[2070]\ttraining's rmse: 2.47723\tvalid_1's rmse: 2.52733\n",
      "[2080]\ttraining's rmse: 2.47423\tvalid_1's rmse: 2.52423\n",
      "[2090]\ttraining's rmse: 2.47287\tvalid_1's rmse: 2.5229\n",
      "[2100]\ttraining's rmse: 2.46953\tvalid_1's rmse: 2.51971\n",
      "[2110]\ttraining's rmse: 2.46664\tvalid_1's rmse: 2.51697\n",
      "[2120]\ttraining's rmse: 2.46348\tvalid_1's rmse: 2.51382\n",
      "[2130]\ttraining's rmse: 2.4605\tvalid_1's rmse: 2.51116\n",
      "[2140]\ttraining's rmse: 2.45837\tvalid_1's rmse: 2.50928\n",
      "[2150]\ttraining's rmse: 2.45672\tvalid_1's rmse: 2.50769\n",
      "[2160]\ttraining's rmse: 2.4543\tvalid_1's rmse: 2.50537\n",
      "[2170]\ttraining's rmse: 2.45168\tvalid_1's rmse: 2.50303\n",
      "[2180]\ttraining's rmse: 2.44947\tvalid_1's rmse: 2.50106\n",
      "[2190]\ttraining's rmse: 2.44665\tvalid_1's rmse: 2.49833\n",
      "[2200]\ttraining's rmse: 2.44389\tvalid_1's rmse: 2.49572\n",
      "[2210]\ttraining's rmse: 2.4418\tvalid_1's rmse: 2.49361\n",
      "[2220]\ttraining's rmse: 2.4383\tvalid_1's rmse: 2.49065\n",
      "[2230]\ttraining's rmse: 2.43534\tvalid_1's rmse: 2.48789\n",
      "[2240]\ttraining's rmse: 2.43204\tvalid_1's rmse: 2.48487\n",
      "[2250]\ttraining's rmse: 2.42972\tvalid_1's rmse: 2.48276\n",
      "[2260]\ttraining's rmse: 2.42853\tvalid_1's rmse: 2.48174\n",
      "[2270]\ttraining's rmse: 2.42618\tvalid_1's rmse: 2.47937\n",
      "[2280]\ttraining's rmse: 2.42485\tvalid_1's rmse: 2.478\n",
      "[2290]\ttraining's rmse: 2.42244\tvalid_1's rmse: 2.47561\n",
      "[2300]\ttraining's rmse: 2.41932\tvalid_1's rmse: 2.47285\n",
      "[2310]\ttraining's rmse: 2.41724\tvalid_1's rmse: 2.47092\n",
      "[2320]\ttraining's rmse: 2.41556\tvalid_1's rmse: 2.46954\n",
      "[2330]\ttraining's rmse: 2.41329\tvalid_1's rmse: 2.46756\n",
      "[2340]\ttraining's rmse: 2.41014\tvalid_1's rmse: 2.46448\n",
      "[2350]\ttraining's rmse: 2.4091\tvalid_1's rmse: 2.46349\n",
      "[2360]\ttraining's rmse: 2.4067\tvalid_1's rmse: 2.46146\n",
      "[2370]\ttraining's rmse: 2.40362\tvalid_1's rmse: 2.45849\n",
      "[2380]\ttraining's rmse: 2.40077\tvalid_1's rmse: 2.45609\n",
      "[2390]\ttraining's rmse: 2.3987\tvalid_1's rmse: 2.45421\n",
      "[2400]\ttraining's rmse: 2.39756\tvalid_1's rmse: 2.45346\n",
      "[2410]\ttraining's rmse: 2.39577\tvalid_1's rmse: 2.45189\n",
      "[2420]\ttraining's rmse: 2.39308\tvalid_1's rmse: 2.44938\n",
      "[2430]\ttraining's rmse: 2.38986\tvalid_1's rmse: 2.44626\n",
      "[2440]\ttraining's rmse: 2.38851\tvalid_1's rmse: 2.44498\n",
      "[2450]\ttraining's rmse: 2.38495\tvalid_1's rmse: 2.44168\n",
      "[2460]\ttraining's rmse: 2.38297\tvalid_1's rmse: 2.43996\n",
      "[2470]\ttraining's rmse: 2.38164\tvalid_1's rmse: 2.43881\n",
      "[2480]\ttraining's rmse: 2.37952\tvalid_1's rmse: 2.43713\n",
      "[2490]\ttraining's rmse: 2.37756\tvalid_1's rmse: 2.43542\n",
      "[2500]\ttraining's rmse: 2.3748\tvalid_1's rmse: 2.43275\n",
      "[2510]\ttraining's rmse: 2.3724\tvalid_1's rmse: 2.43073\n",
      "[2520]\ttraining's rmse: 2.37078\tvalid_1's rmse: 2.42922\n",
      "[2530]\ttraining's rmse: 2.36934\tvalid_1's rmse: 2.42806\n",
      "[2540]\ttraining's rmse: 2.36693\tvalid_1's rmse: 2.42599\n",
      "[2550]\ttraining's rmse: 2.36581\tvalid_1's rmse: 2.42516\n",
      "[2560]\ttraining's rmse: 2.3629\tvalid_1's rmse: 2.42261\n",
      "[2570]\ttraining's rmse: 2.36022\tvalid_1's rmse: 2.42008\n",
      "[2580]\ttraining's rmse: 2.35874\tvalid_1's rmse: 2.41871\n",
      "[2590]\ttraining's rmse: 2.35705\tvalid_1's rmse: 2.41717\n",
      "[2600]\ttraining's rmse: 2.35568\tvalid_1's rmse: 2.41605\n",
      "[2610]\ttraining's rmse: 2.35289\tvalid_1's rmse: 2.41332\n",
      "[2620]\ttraining's rmse: 2.35179\tvalid_1's rmse: 2.41223\n",
      "[2630]\ttraining's rmse: 2.34955\tvalid_1's rmse: 2.41015\n",
      "[2640]\ttraining's rmse: 2.34725\tvalid_1's rmse: 2.40796\n",
      "[2650]\ttraining's rmse: 2.34531\tvalid_1's rmse: 2.40614\n",
      "[2660]\ttraining's rmse: 2.34231\tvalid_1's rmse: 2.4034\n",
      "[2670]\ttraining's rmse: 2.33953\tvalid_1's rmse: 2.40078\n",
      "[2680]\ttraining's rmse: 2.33739\tvalid_1's rmse: 2.39873\n",
      "[2690]\ttraining's rmse: 2.33634\tvalid_1's rmse: 2.39779\n",
      "[2700]\ttraining's rmse: 2.3349\tvalid_1's rmse: 2.39643\n",
      "[2710]\ttraining's rmse: 2.33328\tvalid_1's rmse: 2.39491\n",
      "[2720]\ttraining's rmse: 2.33018\tvalid_1's rmse: 2.39226\n",
      "[2730]\ttraining's rmse: 2.32784\tvalid_1's rmse: 2.39006\n",
      "[2740]\ttraining's rmse: 2.32517\tvalid_1's rmse: 2.38752\n",
      "[2750]\ttraining's rmse: 2.32311\tvalid_1's rmse: 2.38551\n",
      "[2760]\ttraining's rmse: 2.32131\tvalid_1's rmse: 2.38413\n",
      "[2770]\ttraining's rmse: 2.3174\tvalid_1's rmse: 2.38045\n",
      "[2780]\ttraining's rmse: 2.31612\tvalid_1's rmse: 2.37933\n",
      "[2790]\ttraining's rmse: 2.31276\tvalid_1's rmse: 2.3761\n",
      "[2800]\ttraining's rmse: 2.3103\tvalid_1's rmse: 2.37384\n",
      "[2810]\ttraining's rmse: 2.30891\tvalid_1's rmse: 2.37257\n",
      "[2820]\ttraining's rmse: 2.30712\tvalid_1's rmse: 2.37096\n",
      "[2830]\ttraining's rmse: 2.30392\tvalid_1's rmse: 2.36793\n",
      "[2840]\ttraining's rmse: 2.30224\tvalid_1's rmse: 2.36647\n",
      "[2850]\ttraining's rmse: 2.29978\tvalid_1's rmse: 2.36432\n",
      "[2860]\ttraining's rmse: 2.29826\tvalid_1's rmse: 2.36288\n",
      "[2870]\ttraining's rmse: 2.29555\tvalid_1's rmse: 2.36032\n",
      "[2880]\ttraining's rmse: 2.29229\tvalid_1's rmse: 2.35738\n",
      "[2890]\ttraining's rmse: 2.29136\tvalid_1's rmse: 2.35664\n",
      "[2900]\ttraining's rmse: 2.28952\tvalid_1's rmse: 2.35498\n",
      "[2910]\ttraining's rmse: 2.28884\tvalid_1's rmse: 2.35469\n",
      "[2920]\ttraining's rmse: 2.28813\tvalid_1's rmse: 2.3541\n",
      "[2930]\ttraining's rmse: 2.28651\tvalid_1's rmse: 2.35261\n",
      "[2940]\ttraining's rmse: 2.28539\tvalid_1's rmse: 2.35151\n",
      "[2950]\ttraining's rmse: 2.28292\tvalid_1's rmse: 2.34915\n",
      "[2960]\ttraining's rmse: 2.28169\tvalid_1's rmse: 2.34796\n",
      "[2970]\ttraining's rmse: 2.28055\tvalid_1's rmse: 2.347\n",
      "[2980]\ttraining's rmse: 2.2794\tvalid_1's rmse: 2.34632\n",
      "[2990]\ttraining's rmse: 2.2774\tvalid_1's rmse: 2.34473\n",
      "[3000]\ttraining's rmse: 2.27648\tvalid_1's rmse: 2.34406\n",
      "[3010]\ttraining's rmse: 2.27489\tvalid_1's rmse: 2.34272\n",
      "[3020]\ttraining's rmse: 2.27285\tvalid_1's rmse: 2.34102\n",
      "[3030]\ttraining's rmse: 2.27041\tvalid_1's rmse: 2.33866\n",
      "[3040]\ttraining's rmse: 2.26923\tvalid_1's rmse: 2.33752\n",
      "[3050]\ttraining's rmse: 2.26813\tvalid_1's rmse: 2.33679\n",
      "[3060]\ttraining's rmse: 2.26716\tvalid_1's rmse: 2.33599\n",
      "[3070]\ttraining's rmse: 2.26638\tvalid_1's rmse: 2.33539\n",
      "[3080]\ttraining's rmse: 2.26421\tvalid_1's rmse: 2.33328\n",
      "[3090]\ttraining's rmse: 2.26357\tvalid_1's rmse: 2.33285\n",
      "[3100]\ttraining's rmse: 2.26159\tvalid_1's rmse: 2.33089\n",
      "[3110]\ttraining's rmse: 2.25971\tvalid_1's rmse: 2.32905\n",
      "[3120]\ttraining's rmse: 2.25808\tvalid_1's rmse: 2.32763\n",
      "[3130]\ttraining's rmse: 2.25657\tvalid_1's rmse: 2.32628\n",
      "[3140]\ttraining's rmse: 2.2552\tvalid_1's rmse: 2.32508\n",
      "[3150]\ttraining's rmse: 2.25394\tvalid_1's rmse: 2.32399\n",
      "[3160]\ttraining's rmse: 2.25299\tvalid_1's rmse: 2.3231\n",
      "[3170]\ttraining's rmse: 2.25096\tvalid_1's rmse: 2.32116\n",
      "[3180]\ttraining's rmse: 2.24954\tvalid_1's rmse: 2.31975\n",
      "[3190]\ttraining's rmse: 2.24883\tvalid_1's rmse: 2.31911\n",
      "[3200]\ttraining's rmse: 2.24783\tvalid_1's rmse: 2.3182\n",
      "[3210]\ttraining's rmse: 2.24589\tvalid_1's rmse: 2.31643\n",
      "[3220]\ttraining's rmse: 2.24476\tvalid_1's rmse: 2.31563\n",
      "[3230]\ttraining's rmse: 2.24355\tvalid_1's rmse: 2.3145\n",
      "[3240]\ttraining's rmse: 2.2427\tvalid_1's rmse: 2.31342\n",
      "[3250]\ttraining's rmse: 2.24125\tvalid_1's rmse: 2.31228\n",
      "[3260]\ttraining's rmse: 2.24008\tvalid_1's rmse: 2.31128\n",
      "[3270]\ttraining's rmse: 2.23857\tvalid_1's rmse: 2.31\n",
      "[3280]\ttraining's rmse: 2.23667\tvalid_1's rmse: 2.3084\n",
      "[3290]\ttraining's rmse: 2.23496\tvalid_1's rmse: 2.30679\n",
      "[3300]\ttraining's rmse: 2.2332\tvalid_1's rmse: 2.30534\n",
      "[3310]\ttraining's rmse: 2.23186\tvalid_1's rmse: 2.30418\n",
      "[3320]\ttraining's rmse: 2.22977\tvalid_1's rmse: 2.30224\n",
      "[3330]\ttraining's rmse: 2.22809\tvalid_1's rmse: 2.30112\n",
      "[3340]\ttraining's rmse: 2.22717\tvalid_1's rmse: 2.30029\n",
      "[3350]\ttraining's rmse: 2.22605\tvalid_1's rmse: 2.29937\n",
      "[3360]\ttraining's rmse: 2.22401\tvalid_1's rmse: 2.29768\n",
      "[3370]\ttraining's rmse: 2.22271\tvalid_1's rmse: 2.2965\n",
      "[3380]\ttraining's rmse: 2.2219\tvalid_1's rmse: 2.29583\n",
      "[3390]\ttraining's rmse: 2.22074\tvalid_1's rmse: 2.29498\n",
      "[3400]\ttraining's rmse: 2.2195\tvalid_1's rmse: 2.29371\n",
      "[3410]\ttraining's rmse: 2.21881\tvalid_1's rmse: 2.29339\n",
      "[3420]\ttraining's rmse: 2.21739\tvalid_1's rmse: 2.29211\n",
      "[3430]\ttraining's rmse: 2.2156\tvalid_1's rmse: 2.29039\n",
      "[3440]\ttraining's rmse: 2.21402\tvalid_1's rmse: 2.28894\n",
      "[3450]\ttraining's rmse: 2.21322\tvalid_1's rmse: 2.28832\n",
      "[3460]\ttraining's rmse: 2.2119\tvalid_1's rmse: 2.28719\n",
      "[3470]\ttraining's rmse: 2.2101\tvalid_1's rmse: 2.28546\n",
      "[3480]\ttraining's rmse: 2.20966\tvalid_1's rmse: 2.28534\n",
      "[3490]\ttraining's rmse: 2.208\tvalid_1's rmse: 2.28379\n",
      "[3500]\ttraining's rmse: 2.20695\tvalid_1's rmse: 2.28273\n",
      "[3510]\ttraining's rmse: 2.20596\tvalid_1's rmse: 2.282\n",
      "[3520]\ttraining's rmse: 2.20436\tvalid_1's rmse: 2.28043\n",
      "[3530]\ttraining's rmse: 2.20165\tvalid_1's rmse: 2.27802\n",
      "[3540]\ttraining's rmse: 2.2\tvalid_1's rmse: 2.27653\n",
      "[3550]\ttraining's rmse: 2.19879\tvalid_1's rmse: 2.27545\n",
      "[3560]\ttraining's rmse: 2.1977\tvalid_1's rmse: 2.27458\n",
      "[3570]\ttraining's rmse: 2.19631\tvalid_1's rmse: 2.27336\n",
      "[3580]\ttraining's rmse: 2.19536\tvalid_1's rmse: 2.27269\n",
      "[3590]\ttraining's rmse: 2.19361\tvalid_1's rmse: 2.2711\n",
      "[3600]\ttraining's rmse: 2.19169\tvalid_1's rmse: 2.26924\n",
      "[3610]\ttraining's rmse: 2.1906\tvalid_1's rmse: 2.26793\n",
      "[3620]\ttraining's rmse: 2.18889\tvalid_1's rmse: 2.26652\n",
      "[3630]\ttraining's rmse: 2.18665\tvalid_1's rmse: 2.26437\n",
      "[3640]\ttraining's rmse: 2.18517\tvalid_1's rmse: 2.26299\n",
      "[3650]\ttraining's rmse: 2.18352\tvalid_1's rmse: 2.26156\n",
      "[3660]\ttraining's rmse: 2.18142\tvalid_1's rmse: 2.25955\n",
      "[3670]\ttraining's rmse: 2.18091\tvalid_1's rmse: 2.25919\n",
      "[3680]\ttraining's rmse: 2.17953\tvalid_1's rmse: 2.25768\n",
      "[3690]\ttraining's rmse: 2.17864\tvalid_1's rmse: 2.25695\n",
      "[3700]\ttraining's rmse: 2.17784\tvalid_1's rmse: 2.25625\n",
      "[3710]\ttraining's rmse: 2.1763\tvalid_1's rmse: 2.2549\n",
      "[3720]\ttraining's rmse: 2.17435\tvalid_1's rmse: 2.25306\n",
      "[3730]\ttraining's rmse: 2.17172\tvalid_1's rmse: 2.2507\n",
      "[3740]\ttraining's rmse: 2.17024\tvalid_1's rmse: 2.24934\n",
      "[3750]\ttraining's rmse: 2.16781\tvalid_1's rmse: 2.24714\n",
      "[3760]\ttraining's rmse: 2.16692\tvalid_1's rmse: 2.24632\n",
      "[3770]\ttraining's rmse: 2.1656\tvalid_1's rmse: 2.24538\n",
      "[3780]\ttraining's rmse: 2.16344\tvalid_1's rmse: 2.24339\n",
      "[3790]\ttraining's rmse: 2.16291\tvalid_1's rmse: 2.24303\n",
      "[3800]\ttraining's rmse: 2.16114\tvalid_1's rmse: 2.24157\n",
      "[3810]\ttraining's rmse: 2.16054\tvalid_1's rmse: 2.24117\n",
      "[3820]\ttraining's rmse: 2.15844\tvalid_1's rmse: 2.23918\n",
      "[3830]\ttraining's rmse: 2.15734\tvalid_1's rmse: 2.23826\n",
      "[3840]\ttraining's rmse: 2.15633\tvalid_1's rmse: 2.23745\n",
      "[3850]\ttraining's rmse: 2.15349\tvalid_1's rmse: 2.23493\n",
      "[3860]\ttraining's rmse: 2.15257\tvalid_1's rmse: 2.23396\n",
      "[3870]\ttraining's rmse: 2.1515\tvalid_1's rmse: 2.23319\n",
      "[3880]\ttraining's rmse: 2.1508\tvalid_1's rmse: 2.23257\n",
      "[3890]\ttraining's rmse: 2.14981\tvalid_1's rmse: 2.23184\n",
      "[3900]\ttraining's rmse: 2.14808\tvalid_1's rmse: 2.23021\n",
      "[3910]\ttraining's rmse: 2.1468\tvalid_1's rmse: 2.22916\n",
      "[3920]\ttraining's rmse: 2.1458\tvalid_1's rmse: 2.2283\n",
      "[3930]\ttraining's rmse: 2.14508\tvalid_1's rmse: 2.22761\n",
      "[3940]\ttraining's rmse: 2.14302\tvalid_1's rmse: 2.22599\n",
      "[3950]\ttraining's rmse: 2.14158\tvalid_1's rmse: 2.22466\n",
      "[3960]\ttraining's rmse: 2.1389\tvalid_1's rmse: 2.22219\n",
      "[3970]\ttraining's rmse: 2.13781\tvalid_1's rmse: 2.22113\n",
      "[3980]\ttraining's rmse: 2.13674\tvalid_1's rmse: 2.22014\n",
      "[3990]\ttraining's rmse: 2.13599\tvalid_1's rmse: 2.21938\n",
      "[4000]\ttraining's rmse: 2.13543\tvalid_1's rmse: 2.2189\n",
      "[4010]\ttraining's rmse: 2.13412\tvalid_1's rmse: 2.2177\n",
      "[4020]\ttraining's rmse: 2.13301\tvalid_1's rmse: 2.2167\n",
      "[4030]\ttraining's rmse: 2.1312\tvalid_1's rmse: 2.21487\n",
      "[4040]\ttraining's rmse: 2.12943\tvalid_1's rmse: 2.21337\n",
      "[4050]\ttraining's rmse: 2.12827\tvalid_1's rmse: 2.21245\n",
      "[4060]\ttraining's rmse: 2.12699\tvalid_1's rmse: 2.21138\n",
      "[4070]\ttraining's rmse: 2.12635\tvalid_1's rmse: 2.21104\n",
      "[4080]\ttraining's rmse: 2.12471\tvalid_1's rmse: 2.20952\n",
      "[4090]\ttraining's rmse: 2.12378\tvalid_1's rmse: 2.20859\n",
      "[4100]\ttraining's rmse: 2.12284\tvalid_1's rmse: 2.20773\n",
      "[4110]\ttraining's rmse: 2.12113\tvalid_1's rmse: 2.20599\n",
      "[4120]\ttraining's rmse: 2.12002\tvalid_1's rmse: 2.20495\n",
      "[4130]\ttraining's rmse: 2.11849\tvalid_1's rmse: 2.20351\n",
      "[4140]\ttraining's rmse: 2.1171\tvalid_1's rmse: 2.2022\n",
      "[4150]\ttraining's rmse: 2.11517\tvalid_1's rmse: 2.20045\n",
      "[4160]\ttraining's rmse: 2.11379\tvalid_1's rmse: 2.1994\n",
      "[4170]\ttraining's rmse: 2.11292\tvalid_1's rmse: 2.19859\n",
      "[4180]\ttraining's rmse: 2.11126\tvalid_1's rmse: 2.19718\n",
      "[4190]\ttraining's rmse: 2.11035\tvalid_1's rmse: 2.19647\n",
      "[4200]\ttraining's rmse: 2.10978\tvalid_1's rmse: 2.1961\n",
      "[4210]\ttraining's rmse: 2.1086\tvalid_1's rmse: 2.19505\n",
      "[4220]\ttraining's rmse: 2.10806\tvalid_1's rmse: 2.19458\n",
      "[4230]\ttraining's rmse: 2.10707\tvalid_1's rmse: 2.1937\n",
      "[4240]\ttraining's rmse: 2.10682\tvalid_1's rmse: 2.19353\n",
      "[4250]\ttraining's rmse: 2.10586\tvalid_1's rmse: 2.19273\n",
      "[4260]\ttraining's rmse: 2.10455\tvalid_1's rmse: 2.19159\n",
      "[4270]\ttraining's rmse: 2.10322\tvalid_1's rmse: 2.19036\n",
      "[4280]\ttraining's rmse: 2.10244\tvalid_1's rmse: 2.1899\n",
      "[4290]\ttraining's rmse: 2.10074\tvalid_1's rmse: 2.1884\n",
      "[4300]\ttraining's rmse: 2.09956\tvalid_1's rmse: 2.18725\n",
      "[4310]\ttraining's rmse: 2.09875\tvalid_1's rmse: 2.18653\n",
      "[4320]\ttraining's rmse: 2.09757\tvalid_1's rmse: 2.18556\n",
      "[4330]\ttraining's rmse: 2.09692\tvalid_1's rmse: 2.18501\n",
      "[4340]\ttraining's rmse: 2.09623\tvalid_1's rmse: 2.18428\n",
      "[4350]\ttraining's rmse: 2.09555\tvalid_1's rmse: 2.18375\n",
      "[4360]\ttraining's rmse: 2.09364\tvalid_1's rmse: 2.18195\n",
      "[4370]\ttraining's rmse: 2.09281\tvalid_1's rmse: 2.18109\n",
      "[4380]\ttraining's rmse: 2.09238\tvalid_1's rmse: 2.18072\n",
      "[4390]\ttraining's rmse: 2.09148\tvalid_1's rmse: 2.1801\n",
      "[4400]\ttraining's rmse: 2.09003\tvalid_1's rmse: 2.17865\n",
      "[4410]\ttraining's rmse: 2.08904\tvalid_1's rmse: 2.17786\n",
      "[4420]\ttraining's rmse: 2.08794\tvalid_1's rmse: 2.17683\n",
      "[4430]\ttraining's rmse: 2.08657\tvalid_1's rmse: 2.17551\n",
      "[4440]\ttraining's rmse: 2.08589\tvalid_1's rmse: 2.17499\n",
      "[4450]\ttraining's rmse: 2.08564\tvalid_1's rmse: 2.17473\n",
      "[4460]\ttraining's rmse: 2.08435\tvalid_1's rmse: 2.17353\n",
      "[4470]\ttraining's rmse: 2.08367\tvalid_1's rmse: 2.17292\n",
      "[4480]\ttraining's rmse: 2.08254\tvalid_1's rmse: 2.17235\n",
      "[4490]\ttraining's rmse: 2.08109\tvalid_1's rmse: 2.17098\n",
      "[4500]\ttraining's rmse: 2.08054\tvalid_1's rmse: 2.17064\n",
      "[4510]\ttraining's rmse: 2.07917\tvalid_1's rmse: 2.16938\n",
      "[4520]\ttraining's rmse: 2.07694\tvalid_1's rmse: 2.1673\n",
      "[4530]\ttraining's rmse: 2.07572\tvalid_1's rmse: 2.16626\n",
      "[4540]\ttraining's rmse: 2.07418\tvalid_1's rmse: 2.16503\n",
      "[4550]\ttraining's rmse: 2.07305\tvalid_1's rmse: 2.16418\n",
      "[4560]\ttraining's rmse: 2.07247\tvalid_1's rmse: 2.16397\n",
      "[4570]\ttraining's rmse: 2.07144\tvalid_1's rmse: 2.16324\n",
      "[4580]\ttraining's rmse: 2.06971\tvalid_1's rmse: 2.16184\n",
      "[4590]\ttraining's rmse: 2.06748\tvalid_1's rmse: 2.1602\n",
      "[4600]\ttraining's rmse: 2.06611\tvalid_1's rmse: 2.15896\n",
      "[4610]\ttraining's rmse: 2.0654\tvalid_1's rmse: 2.15844\n",
      "[4620]\ttraining's rmse: 2.0646\tvalid_1's rmse: 2.15777\n",
      "[4630]\ttraining's rmse: 2.06361\tvalid_1's rmse: 2.15696\n",
      "[4640]\ttraining's rmse: 2.06303\tvalid_1's rmse: 2.15647\n",
      "[4650]\ttraining's rmse: 2.0614\tvalid_1's rmse: 2.15491\n",
      "[4660]\ttraining's rmse: 2.06052\tvalid_1's rmse: 2.15415\n",
      "[4670]\ttraining's rmse: 2.0592\tvalid_1's rmse: 2.15289\n",
      "[4680]\ttraining's rmse: 2.05827\tvalid_1's rmse: 2.15201\n",
      "[4690]\ttraining's rmse: 2.05725\tvalid_1's rmse: 2.15118\n",
      "[4700]\ttraining's rmse: 2.05658\tvalid_1's rmse: 2.15097\n",
      "[4710]\ttraining's rmse: 2.05556\tvalid_1's rmse: 2.15018\n",
      "[4720]\ttraining's rmse: 2.05458\tvalid_1's rmse: 2.14942\n",
      "[4730]\ttraining's rmse: 2.05357\tvalid_1's rmse: 2.1487\n",
      "[4740]\ttraining's rmse: 2.05319\tvalid_1's rmse: 2.14834\n",
      "[4750]\ttraining's rmse: 2.0523\tvalid_1's rmse: 2.14752\n",
      "[4760]\ttraining's rmse: 2.05165\tvalid_1's rmse: 2.14699\n",
      "[4770]\ttraining's rmse: 2.0512\tvalid_1's rmse: 2.14663\n",
      "[4780]\ttraining's rmse: 2.05025\tvalid_1's rmse: 2.14582\n",
      "[4790]\ttraining's rmse: 2.05002\tvalid_1's rmse: 2.14568\n",
      "[4800]\ttraining's rmse: 2.04907\tvalid_1's rmse: 2.14479\n",
      "[4810]\ttraining's rmse: 2.04843\tvalid_1's rmse: 2.14424\n",
      "[4820]\ttraining's rmse: 2.04739\tvalid_1's rmse: 2.14329\n",
      "[4830]\ttraining's rmse: 2.04693\tvalid_1's rmse: 2.14306\n",
      "[4840]\ttraining's rmse: 2.04617\tvalid_1's rmse: 2.14249\n",
      "[4850]\ttraining's rmse: 2.04543\tvalid_1's rmse: 2.14182\n",
      "[4860]\ttraining's rmse: 2.0446\tvalid_1's rmse: 2.14122\n",
      "[4870]\ttraining's rmse: 2.04356\tvalid_1's rmse: 2.14049\n",
      "[4880]\ttraining's rmse: 2.04225\tvalid_1's rmse: 2.13938\n",
      "[4890]\ttraining's rmse: 2.04184\tvalid_1's rmse: 2.13895\n",
      "[4900]\ttraining's rmse: 2.04153\tvalid_1's rmse: 2.13879\n",
      "[4910]\ttraining's rmse: 2.04051\tvalid_1's rmse: 2.13796\n",
      "[4920]\ttraining's rmse: 2.03994\tvalid_1's rmse: 2.13758\n",
      "[4930]\ttraining's rmse: 2.03896\tvalid_1's rmse: 2.13668\n",
      "[4940]\ttraining's rmse: 2.03843\tvalid_1's rmse: 2.13626\n",
      "[4950]\ttraining's rmse: 2.03725\tvalid_1's rmse: 2.13538\n",
      "[4960]\ttraining's rmse: 2.03638\tvalid_1's rmse: 2.13464\n",
      "[4970]\ttraining's rmse: 2.03598\tvalid_1's rmse: 2.13432\n",
      "[4980]\ttraining's rmse: 2.03526\tvalid_1's rmse: 2.13365\n",
      "[4990]\ttraining's rmse: 2.03419\tvalid_1's rmse: 2.13261\n",
      "[5000]\ttraining's rmse: 2.0336\tvalid_1's rmse: 2.13212\n",
      "[5010]\ttraining's rmse: 2.03296\tvalid_1's rmse: 2.13145\n",
      "[5020]\ttraining's rmse: 2.03168\tvalid_1's rmse: 2.13019\n",
      "[5030]\ttraining's rmse: 2.0308\tvalid_1's rmse: 2.12981\n",
      "[5040]\ttraining's rmse: 2.02933\tvalid_1's rmse: 2.12837\n",
      "[5050]\ttraining's rmse: 2.02817\tvalid_1's rmse: 2.12736\n",
      "[5060]\ttraining's rmse: 2.02718\tvalid_1's rmse: 2.12648\n",
      "[5070]\ttraining's rmse: 2.02662\tvalid_1's rmse: 2.12586\n",
      "[5080]\ttraining's rmse: 2.02578\tvalid_1's rmse: 2.12531\n",
      "[5090]\ttraining's rmse: 2.02429\tvalid_1's rmse: 2.1239\n",
      "[5100]\ttraining's rmse: 2.02318\tvalid_1's rmse: 2.12286\n",
      "[5110]\ttraining's rmse: 2.02288\tvalid_1's rmse: 2.1227\n",
      "[5120]\ttraining's rmse: 2.02207\tvalid_1's rmse: 2.12211\n",
      "[5130]\ttraining's rmse: 2.02117\tvalid_1's rmse: 2.12127\n",
      "[5140]\ttraining's rmse: 2.02071\tvalid_1's rmse: 2.12093\n",
      "[5150]\ttraining's rmse: 2.02009\tvalid_1's rmse: 2.12009\n",
      "[5160]\ttraining's rmse: 2.01889\tvalid_1's rmse: 2.11895\n",
      "[5170]\ttraining's rmse: 2.01812\tvalid_1's rmse: 2.11829\n",
      "[5180]\ttraining's rmse: 2.01714\tvalid_1's rmse: 2.1175\n",
      "[5190]\ttraining's rmse: 2.01653\tvalid_1's rmse: 2.11695\n",
      "[5200]\ttraining's rmse: 2.0159\tvalid_1's rmse: 2.11643\n",
      "[5210]\ttraining's rmse: 2.01538\tvalid_1's rmse: 2.11624\n",
      "[5220]\ttraining's rmse: 2.01482\tvalid_1's rmse: 2.11591\n",
      "[5230]\ttraining's rmse: 2.01346\tvalid_1's rmse: 2.11472\n",
      "[5240]\ttraining's rmse: 2.01211\tvalid_1's rmse: 2.11377\n",
      "[5250]\ttraining's rmse: 2.01163\tvalid_1's rmse: 2.11354\n",
      "[5260]\ttraining's rmse: 2.01116\tvalid_1's rmse: 2.11321\n",
      "[5270]\ttraining's rmse: 2.01026\tvalid_1's rmse: 2.1123\n",
      "[5280]\ttraining's rmse: 2.00965\tvalid_1's rmse: 2.11191\n",
      "[5290]\ttraining's rmse: 2.00873\tvalid_1's rmse: 2.11111\n",
      "[5300]\ttraining's rmse: 2.00779\tvalid_1's rmse: 2.1101\n",
      "[5310]\ttraining's rmse: 2.00611\tvalid_1's rmse: 2.10858\n",
      "[5320]\ttraining's rmse: 2.00518\tvalid_1's rmse: 2.10785\n",
      "[5330]\ttraining's rmse: 2.00432\tvalid_1's rmse: 2.10714\n",
      "[5340]\ttraining's rmse: 2.00321\tvalid_1's rmse: 2.10624\n",
      "[5350]\ttraining's rmse: 2.0026\tvalid_1's rmse: 2.10584\n",
      "[5360]\ttraining's rmse: 2.00145\tvalid_1's rmse: 2.10488\n",
      "[5370]\ttraining's rmse: 2.00083\tvalid_1's rmse: 2.10431\n",
      "[5380]\ttraining's rmse: 1.99968\tvalid_1's rmse: 2.10309\n",
      "[5390]\ttraining's rmse: 1.99903\tvalid_1's rmse: 2.10244\n",
      "[5400]\ttraining's rmse: 1.99768\tvalid_1's rmse: 2.10137\n",
      "[5410]\ttraining's rmse: 1.99655\tvalid_1's rmse: 2.10064\n",
      "[5420]\ttraining's rmse: 1.99569\tvalid_1's rmse: 2.09986\n",
      "[5430]\ttraining's rmse: 1.99534\tvalid_1's rmse: 2.09959\n",
      "[5440]\ttraining's rmse: 1.99491\tvalid_1's rmse: 2.09916\n",
      "[5450]\ttraining's rmse: 1.99457\tvalid_1's rmse: 2.09887\n",
      "[5460]\ttraining's rmse: 1.99365\tvalid_1's rmse: 2.09807\n",
      "[5470]\ttraining's rmse: 1.99251\tvalid_1's rmse: 2.09706\n",
      "[5480]\ttraining's rmse: 1.99142\tvalid_1's rmse: 2.09613\n",
      "[5490]\ttraining's rmse: 1.99078\tvalid_1's rmse: 2.09557\n",
      "[5500]\ttraining's rmse: 1.99025\tvalid_1's rmse: 2.09511\n",
      "[5510]\ttraining's rmse: 1.98924\tvalid_1's rmse: 2.09423\n",
      "[5520]\ttraining's rmse: 1.98876\tvalid_1's rmse: 2.09388\n",
      "[5530]\ttraining's rmse: 1.98807\tvalid_1's rmse: 2.09323\n",
      "[5540]\ttraining's rmse: 1.98689\tvalid_1's rmse: 2.09219\n",
      "[5550]\ttraining's rmse: 1.98543\tvalid_1's rmse: 2.09103\n",
      "[5560]\ttraining's rmse: 1.98469\tvalid_1's rmse: 2.0904\n",
      "[5570]\ttraining's rmse: 1.98399\tvalid_1's rmse: 2.08988\n",
      "[5580]\ttraining's rmse: 1.98328\tvalid_1's rmse: 2.08939\n",
      "[5590]\ttraining's rmse: 1.98268\tvalid_1's rmse: 2.08886\n",
      "[5600]\ttraining's rmse: 1.98222\tvalid_1's rmse: 2.08843\n",
      "[5610]\ttraining's rmse: 1.98181\tvalid_1's rmse: 2.08813\n",
      "[5620]\ttraining's rmse: 1.98088\tvalid_1's rmse: 2.08725\n",
      "[5630]\ttraining's rmse: 1.98011\tvalid_1's rmse: 2.08651\n",
      "[5640]\ttraining's rmse: 1.97982\tvalid_1's rmse: 2.08634\n",
      "[5650]\ttraining's rmse: 1.979\tvalid_1's rmse: 2.08572\n",
      "[5660]\ttraining's rmse: 1.97802\tvalid_1's rmse: 2.08504\n",
      "[5670]\ttraining's rmse: 1.97688\tvalid_1's rmse: 2.08388\n",
      "[5680]\ttraining's rmse: 1.97632\tvalid_1's rmse: 2.08355\n",
      "[5690]\ttraining's rmse: 1.97563\tvalid_1's rmse: 2.08293\n",
      "[5700]\ttraining's rmse: 1.97506\tvalid_1's rmse: 2.08233\n",
      "[5710]\ttraining's rmse: 1.97415\tvalid_1's rmse: 2.08153\n",
      "[5720]\ttraining's rmse: 1.97341\tvalid_1's rmse: 2.08099\n",
      "[5730]\ttraining's rmse: 1.97175\tvalid_1's rmse: 2.07939\n",
      "[5740]\ttraining's rmse: 1.97126\tvalid_1's rmse: 2.07893\n",
      "[5750]\ttraining's rmse: 1.97019\tvalid_1's rmse: 2.07806\n",
      "[5760]\ttraining's rmse: 1.96997\tvalid_1's rmse: 2.0779\n",
      "[5770]\ttraining's rmse: 1.96921\tvalid_1's rmse: 2.07758\n",
      "[5780]\ttraining's rmse: 1.96879\tvalid_1's rmse: 2.07722\n",
      "[5790]\ttraining's rmse: 1.96813\tvalid_1's rmse: 2.07657\n",
      "[5800]\ttraining's rmse: 1.96722\tvalid_1's rmse: 2.07577\n",
      "[5810]\ttraining's rmse: 1.96655\tvalid_1's rmse: 2.07542\n",
      "[5820]\ttraining's rmse: 1.96616\tvalid_1's rmse: 2.07509\n",
      "[5830]\ttraining's rmse: 1.96575\tvalid_1's rmse: 2.07478\n",
      "[5840]\ttraining's rmse: 1.96531\tvalid_1's rmse: 2.07445\n",
      "[5850]\ttraining's rmse: 1.96464\tvalid_1's rmse: 2.07385\n",
      "[5860]\ttraining's rmse: 1.96371\tvalid_1's rmse: 2.07301\n",
      "[5870]\ttraining's rmse: 1.96308\tvalid_1's rmse: 2.0724\n",
      "[5880]\ttraining's rmse: 1.96193\tvalid_1's rmse: 2.07138\n",
      "[5890]\ttraining's rmse: 1.96157\tvalid_1's rmse: 2.07117\n",
      "[5900]\ttraining's rmse: 1.961\tvalid_1's rmse: 2.07075\n",
      "[5910]\ttraining's rmse: 1.96051\tvalid_1's rmse: 2.0704\n",
      "[5920]\ttraining's rmse: 1.96026\tvalid_1's rmse: 2.0703\n",
      "[5930]\ttraining's rmse: 1.9598\tvalid_1's rmse: 2.06986\n",
      "[5940]\ttraining's rmse: 1.95959\tvalid_1's rmse: 2.06981\n",
      "[5950]\ttraining's rmse: 1.95898\tvalid_1's rmse: 2.06934\n",
      "[5960]\ttraining's rmse: 1.95858\tvalid_1's rmse: 2.06891\n",
      "[5970]\ttraining's rmse: 1.95752\tvalid_1's rmse: 2.06804\n",
      "[5980]\ttraining's rmse: 1.95697\tvalid_1's rmse: 2.06756\n",
      "[5990]\ttraining's rmse: 1.95626\tvalid_1's rmse: 2.06684\n",
      "[6000]\ttraining's rmse: 1.95553\tvalid_1's rmse: 2.06612\n",
      "[6010]\ttraining's rmse: 1.95513\tvalid_1's rmse: 2.06582\n",
      "[6020]\ttraining's rmse: 1.95393\tvalid_1's rmse: 2.06488\n",
      "[6030]\ttraining's rmse: 1.95333\tvalid_1's rmse: 2.06449\n",
      "[6040]\ttraining's rmse: 1.95294\tvalid_1's rmse: 2.06421\n",
      "[6050]\ttraining's rmse: 1.95213\tvalid_1's rmse: 2.06339\n",
      "[6060]\ttraining's rmse: 1.9515\tvalid_1's rmse: 2.0628\n",
      "[6070]\ttraining's rmse: 1.95124\tvalid_1's rmse: 2.06261\n",
      "[6080]\ttraining's rmse: 1.95089\tvalid_1's rmse: 2.06229\n",
      "[6090]\ttraining's rmse: 1.95049\tvalid_1's rmse: 2.0621\n",
      "[6100]\ttraining's rmse: 1.94994\tvalid_1's rmse: 2.06172\n",
      "[6110]\ttraining's rmse: 1.94967\tvalid_1's rmse: 2.06155\n",
      "[6120]\ttraining's rmse: 1.9494\tvalid_1's rmse: 2.06137\n",
      "[6130]\ttraining's rmse: 1.94888\tvalid_1's rmse: 2.06091\n",
      "[6140]\ttraining's rmse: 1.94836\tvalid_1's rmse: 2.06049\n",
      "[6150]\ttraining's rmse: 1.94806\tvalid_1's rmse: 2.06024\n",
      "[6160]\ttraining's rmse: 1.94755\tvalid_1's rmse: 2.05983\n",
      "[6170]\ttraining's rmse: 1.94705\tvalid_1's rmse: 2.05944\n",
      "[6180]\ttraining's rmse: 1.94569\tvalid_1's rmse: 2.05811\n",
      "[6190]\ttraining's rmse: 1.94475\tvalid_1's rmse: 2.05722\n",
      "[6200]\ttraining's rmse: 1.94396\tvalid_1's rmse: 2.0565\n",
      "[6210]\ttraining's rmse: 1.94316\tvalid_1's rmse: 2.05577\n",
      "[6220]\ttraining's rmse: 1.94275\tvalid_1's rmse: 2.05551\n",
      "[6230]\ttraining's rmse: 1.94243\tvalid_1's rmse: 2.05526\n",
      "[6240]\ttraining's rmse: 1.94182\tvalid_1's rmse: 2.0548\n",
      "[6250]\ttraining's rmse: 1.94141\tvalid_1's rmse: 2.05442\n",
      "[6260]\ttraining's rmse: 1.94103\tvalid_1's rmse: 2.05426\n",
      "[6270]\ttraining's rmse: 1.94029\tvalid_1's rmse: 2.05397\n",
      "[6280]\ttraining's rmse: 1.9391\tvalid_1's rmse: 2.05292\n",
      "[6290]\ttraining's rmse: 1.9385\tvalid_1's rmse: 2.05255\n",
      "[6300]\ttraining's rmse: 1.93798\tvalid_1's rmse: 2.05212\n",
      "[6310]\ttraining's rmse: 1.93733\tvalid_1's rmse: 2.05153\n",
      "[6320]\ttraining's rmse: 1.93708\tvalid_1's rmse: 2.0513\n",
      "[6330]\ttraining's rmse: 1.93693\tvalid_1's rmse: 2.05124\n",
      "[6340]\ttraining's rmse: 1.93672\tvalid_1's rmse: 2.05103\n",
      "[6350]\ttraining's rmse: 1.93613\tvalid_1's rmse: 2.0505\n",
      "[6360]\ttraining's rmse: 1.93541\tvalid_1's rmse: 2.05006\n",
      "[6370]\ttraining's rmse: 1.93503\tvalid_1's rmse: 2.0499\n",
      "[6380]\ttraining's rmse: 1.93453\tvalid_1's rmse: 2.04939\n",
      "[6390]\ttraining's rmse: 1.93415\tvalid_1's rmse: 2.04923\n",
      "[6400]\ttraining's rmse: 1.9338\tvalid_1's rmse: 2.04903\n",
      "[6410]\ttraining's rmse: 1.93347\tvalid_1's rmse: 2.04874\n",
      "[6420]\ttraining's rmse: 1.93285\tvalid_1's rmse: 2.04826\n",
      "[6430]\ttraining's rmse: 1.93253\tvalid_1's rmse: 2.04805\n",
      "[6440]\ttraining's rmse: 1.9315\tvalid_1's rmse: 2.04716\n",
      "[6450]\ttraining's rmse: 1.93067\tvalid_1's rmse: 2.04646\n",
      "[6460]\ttraining's rmse: 1.93005\tvalid_1's rmse: 2.04587\n",
      "[6470]\ttraining's rmse: 1.92891\tvalid_1's rmse: 2.04486\n",
      "[6480]\ttraining's rmse: 1.92845\tvalid_1's rmse: 2.04462\n",
      "[6490]\ttraining's rmse: 1.92744\tvalid_1's rmse: 2.04366\n",
      "[6500]\ttraining's rmse: 1.92721\tvalid_1's rmse: 2.04349\n",
      "[6510]\ttraining's rmse: 1.92658\tvalid_1's rmse: 2.04311\n",
      "[6520]\ttraining's rmse: 1.92623\tvalid_1's rmse: 2.0428\n",
      "[6530]\ttraining's rmse: 1.92597\tvalid_1's rmse: 2.04264\n",
      "[6540]\ttraining's rmse: 1.92549\tvalid_1's rmse: 2.0423\n",
      "[6550]\ttraining's rmse: 1.9246\tvalid_1's rmse: 2.04159\n",
      "[6560]\ttraining's rmse: 1.92406\tvalid_1's rmse: 2.04111\n",
      "[6570]\ttraining's rmse: 1.92349\tvalid_1's rmse: 2.0407\n",
      "[6580]\ttraining's rmse: 1.92296\tvalid_1's rmse: 2.04035\n",
      "[6590]\ttraining's rmse: 1.92251\tvalid_1's rmse: 2.03992\n",
      "[6600]\ttraining's rmse: 1.92176\tvalid_1's rmse: 2.0394\n",
      "[6610]\ttraining's rmse: 1.92063\tvalid_1's rmse: 2.03841\n",
      "[6620]\ttraining's rmse: 1.92014\tvalid_1's rmse: 2.03825\n",
      "[6630]\ttraining's rmse: 1.91931\tvalid_1's rmse: 2.03748\n",
      "[6640]\ttraining's rmse: 1.91806\tvalid_1's rmse: 2.03616\n",
      "[6650]\ttraining's rmse: 1.91759\tvalid_1's rmse: 2.03608\n",
      "[6660]\ttraining's rmse: 1.91726\tvalid_1's rmse: 2.03596\n",
      "[6670]\ttraining's rmse: 1.91615\tvalid_1's rmse: 2.035\n",
      "[6680]\ttraining's rmse: 1.91592\tvalid_1's rmse: 2.03486\n",
      "[6690]\ttraining's rmse: 1.91538\tvalid_1's rmse: 2.03444\n",
      "[6700]\ttraining's rmse: 1.9149\tvalid_1's rmse: 2.03408\n",
      "[6710]\ttraining's rmse: 1.91436\tvalid_1's rmse: 2.0336\n",
      "[6720]\ttraining's rmse: 1.91392\tvalid_1's rmse: 2.03333\n",
      "[6730]\ttraining's rmse: 1.91359\tvalid_1's rmse: 2.03304\n",
      "[6740]\ttraining's rmse: 1.91316\tvalid_1's rmse: 2.03269\n",
      "[6750]\ttraining's rmse: 1.91222\tvalid_1's rmse: 2.03182\n",
      "[6760]\ttraining's rmse: 1.9118\tvalid_1's rmse: 2.03159\n",
      "[6770]\ttraining's rmse: 1.91142\tvalid_1's rmse: 2.03139\n",
      "[6780]\ttraining's rmse: 1.91072\tvalid_1's rmse: 2.03064\n",
      "[6790]\ttraining's rmse: 1.91004\tvalid_1's rmse: 2.0302\n",
      "[6800]\ttraining's rmse: 1.90924\tvalid_1's rmse: 2.02945\n",
      "[6810]\ttraining's rmse: 1.90873\tvalid_1's rmse: 2.02901\n",
      "[6820]\ttraining's rmse: 1.90833\tvalid_1's rmse: 2.02871\n",
      "[6830]\ttraining's rmse: 1.90755\tvalid_1's rmse: 2.0281\n",
      "[6840]\ttraining's rmse: 1.9073\tvalid_1's rmse: 2.02793\n",
      "[6850]\ttraining's rmse: 1.90704\tvalid_1's rmse: 2.02776\n",
      "[6860]\ttraining's rmse: 1.90635\tvalid_1's rmse: 2.02721\n",
      "[6870]\ttraining's rmse: 1.9061\tvalid_1's rmse: 2.02718\n",
      "[6880]\ttraining's rmse: 1.90584\tvalid_1's rmse: 2.02702\n",
      "[6890]\ttraining's rmse: 1.90561\tvalid_1's rmse: 2.0269\n",
      "[6900]\ttraining's rmse: 1.90448\tvalid_1's rmse: 2.02592\n",
      "[6910]\ttraining's rmse: 1.90403\tvalid_1's rmse: 2.02561\n",
      "[6920]\ttraining's rmse: 1.90387\tvalid_1's rmse: 2.02549\n",
      "[6930]\ttraining's rmse: 1.90337\tvalid_1's rmse: 2.02511\n",
      "[6940]\ttraining's rmse: 1.9028\tvalid_1's rmse: 2.02455\n",
      "[6950]\ttraining's rmse: 1.90239\tvalid_1's rmse: 2.02422\n",
      "[6960]\ttraining's rmse: 1.90194\tvalid_1's rmse: 2.02402\n",
      "[6970]\ttraining's rmse: 1.90134\tvalid_1's rmse: 2.02344\n",
      "[6980]\ttraining's rmse: 1.90008\tvalid_1's rmse: 2.0225\n",
      "[6990]\ttraining's rmse: 1.89968\tvalid_1's rmse: 2.02231\n",
      "[7000]\ttraining's rmse: 1.89878\tvalid_1's rmse: 2.02154\n",
      "[7010]\ttraining's rmse: 1.89863\tvalid_1's rmse: 2.02147\n",
      "[7020]\ttraining's rmse: 1.89779\tvalid_1's rmse: 2.02095\n",
      "[7030]\ttraining's rmse: 1.89734\tvalid_1's rmse: 2.02072\n",
      "[7040]\ttraining's rmse: 1.8971\tvalid_1's rmse: 2.02059\n",
      "[7050]\ttraining's rmse: 1.89607\tvalid_1's rmse: 2.01971\n",
      "[7060]\ttraining's rmse: 1.89591\tvalid_1's rmse: 2.01962\n",
      "[7070]\ttraining's rmse: 1.8955\tvalid_1's rmse: 2.01933\n",
      "[7080]\ttraining's rmse: 1.89486\tvalid_1's rmse: 2.01898\n",
      "[7090]\ttraining's rmse: 1.89382\tvalid_1's rmse: 2.01791\n",
      "[7100]\ttraining's rmse: 1.89339\tvalid_1's rmse: 2.01751\n",
      "[7110]\ttraining's rmse: 1.89296\tvalid_1's rmse: 2.01712\n",
      "Early stopping, best iteration is:\n",
      "[7109]\ttraining's rmse: 1.89301\tvalid_1's rmse: 2.01711\n"
     ]
    }
   ],
   "source": [
    "X=pd.concat([X,X_test])\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Now, concatenate y and y_test_series\n",
    "y = pd.concat([y, y_test_series])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "# Continue with fitting the model as before\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    valid_sets=[train_data, val_data],\n",
    "                    callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)])  # Print progress\n",
    "\n",
    "# Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_11212\\3429583794.py:1: DtypeWarning: Columns (13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd_final = pd.read_csv(\"test.csv\")\n"
     ]
    }
   ],
   "source": [
    "pd_final = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.61261799  4.41565168  6.12657317 ... 10.88282332  9.87722078\n",
      " 10.63823114]\n"
     ]
    }
   ],
   "source": [
    "pd_final = pd_final[X.columns]\n",
    "\n",
    "# Predict the class for each row in pd_final\n",
    "predictions = model.predict(pd_final)\n",
    "\n",
    "# Increment the predictions by 1 to shift the range from 0-19 to 1-20\n",
    "adjusted_predictions = predictions + 1\n",
    "\n",
    "# Print the adjusted predictions\n",
    "print(adjusted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352928,)\n"
     ]
    }
   ],
   "source": [
    "print(adjusted_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 298739826  299218806  299697786 ... 1881902325 1882424025 1882971810]\n"
     ]
    }
   ],
   "source": [
    "result_driver_standing_array = pd_final['result_driver_standing'].values\n",
    "print(result_driver_standing_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        predictions  result_driver_standing\n",
      "0          4.612618               298739826\n",
      "1          4.415652               299218806\n",
      "2          6.126573               299697786\n",
      "3          4.903401               300176766\n",
      "4          4.903401               300655746\n",
      "...             ...                     ...\n",
      "352923    16.285059              1880337225\n",
      "352924    16.285059              1881380625\n",
      "352925    10.882823              1881902325\n",
      "352926     9.877221              1882424025\n",
      "352927    10.638231              1882971810\n",
      "\n",
      "[352928 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame from the two arrays\n",
    "df_sub = pd.DataFrame({\n",
    "    'predictions': adjusted_predictions,\n",
    "    'result_driver_standing': result_driver_standing_array\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
